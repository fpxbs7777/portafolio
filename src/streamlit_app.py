import streamlit as st
import requests
import plotly.graph_objects as go
import pandas as pd
from plotly.subplots import make_subplots
from datetime import date, timedelta, datetime
import numpy as np
import yfinance as yf
import scipy.optimize as op
from scipy import stats # Added for skewness, kurtosis, jarque_bera
import random
import warnings
# --- NUEVAS IMPORTACIONES PARA MACHINE LEARNING ---
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge, Lasso
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.neural_network import MLPRegressor, MLPClassifier
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.metrics import mean_squared_error, r2_score, classification_report
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from sklearn.svm import SVR, SVC
from sklearn.cluster import KMeans
import seaborn as sns

warnings.filterwarnings('ignore')

# Configuraci√≥n de la p√°gina
st.set_page_config(
    page_title="IOL Portfolio Analyzer",
    page_icon="üìä",
    layout="wide"
)

def obtener_encabezado_autorizacion(token_portador):
    return {
        'Authorization': f'Bearer {token_portador}',
        'Content-Type': 'application/json'
    }

def obtener_tokens(usuario, contrase√±a):
    url_login = 'https://api.invertironline.com/token'
    datos = {
        'username': usuario,
        'password': contrase√±a,
        'grant_type': 'password'
    }
    try:
        respuesta = requests.post(url_login, data=datos, timeout=15) # Added timeout
        respuesta.raise_for_status() # Raises HTTPError for bad responses (4xx or 5xx)
        respuesta_json = respuesta.json()
        return respuesta_json['access_token'], respuesta_json['refresh_token']
    except requests.exceptions.HTTPError as http_err:
        st.error(f'Error HTTP al obtener tokens: {http_err}')
        if respuesta.status_code == 400:
            st.warning("Verifique sus credenciales (usuario/contrase√±a). El servidor indic√≥ 'Bad Request'.")
        elif respuesta.status_code == 401:
            st.warning("No autorizado. Verifique sus credenciales o permisos.")
        else:
            st.warning(f"El servidor de IOL devolvi√≥ un error. C√≥digo de estado: {respuesta.status_code}.")
        return None, None
    except requests.exceptions.ConnectionError as conn_err:
        st.error(f'Error de conexi√≥n al intentar obtener tokens: {conn_err}')
        st.warning("No se pudo conectar al servidor de IOL. Verifique su conexi√≥n a internet y que el servicio de IOL est√© disponible.")
        return None, None
    except requests.exceptions.Timeout as timeout_err:
        st.error(f'Timeout al intentar obtener tokens: {timeout_err}')
        st.warning("La solicitud a IOL tard√≥ demasiado en responder. Intente m√°s tarde.")
        return None, None
    except requests.exceptions.RequestException as req_err: # Catch any other requests error
        st.error(f'Error en la solicitud al obtener tokens: {req_err}')
        return None, None
    except Exception as e: # General fallback
        st.error(f'Error inesperado al obtener tokens: {str(e)}')
        return None, None

def obtener_lista_clientes(token_portador):
    url_clientes = 'https://api.invertironline.com/api/v2/Asesores/Clientes'
    encabezados = obtener_encabezado_autorizacion(token_portador)
    try:
        respuesta = requests.get(url_clientes, headers=encabezados)
        if respuesta.status_code == 200:
            clientes_data = respuesta.json()
            # Debug: mostrar estructura de respuesta
            st.info(f"üìã Estructura de respuesta de clientes: {type(clientes_data)}")
            if isinstance(clientes_data, list):
                return clientes_data
            elif isinstance(clientes_data, dict) and 'clientes' in clientes_data:
                return clientes_data['clientes']
            else:
                st.warning(f"Estructura de datos inesperada: {clientes_data}")
                return []
        else:
            st.error(f'Error al obtener la lista de clientes: {respuesta.status_code}')
            st.error(f'Respuesta: {respuesta.text}')
            return []
    except Exception as e:
        st.error(f'Error de conexi√≥n al obtener clientes: {str(e)}')
        return []

def obtener_estado_cuenta(token_portador, id_cliente=None):
    """
    Obtiene el estado de cuenta del usuario autenticado o cliente espec√≠fico
    """
    # Usar endpoint directo para usuario autenticado o endpoint de asesor para cliente espec√≠fico
    if id_cliente:
        url_estado_cuenta = f'https://api.invertironline.com/api/v2/Asesores/EstadoDeCuenta/{id_cliente}'
    else:
        url_estado_cuenta = 'https://api.invertironline.com/api/v2/estadocuenta'
    
    encabezados = obtener_encabezado_autorizacion(token_portador)
    try:
        respuesta = requests.get(url_estado_cuenta, headers=encabezados)
        # Eliminar mensajes de interfaz innecesarios
        # st.info(f"üí∞ Solicitando estado de cuenta - URL: {url_estado_cuenta}")
        # st.info(f"üìä Status Code: {respuesta.status_code}")
        
        if respuesta.status_code == 200:
            estado_data = respuesta.json()
            # st.success(f"‚úÖ Estado de cuenta obtenido exitosamente")
            return estado_data
        elif respuesta.status_code == 401:
            st.warning(f"üîê No autorizado - Token inv√°lido o permisos insuficientes")
            if id_cliente:
                st.info("üí° Intentando con endpoint directo sin ID de cliente...")
                # Intentar con endpoint directo
                return obtener_estado_cuenta(token_portador, None)
            return None
        elif respuesta.status_code == 404:
            st.warning(f"‚ö†Ô∏è Estado de cuenta no encontrado")
            return None
        else:
            st.error(f'‚ùå Error al obtener estado de cuenta: {respuesta.status_code}')
            st.error(f'üìÑ Respuesta: {respuesta.text}')
            return None
    except Exception as e:
        st.error(f'üí• Error de conexi√≥n al obtener estado de cuenta: {str(e)}')
        return None

def obtener_portafolio(token_portador, id_cliente, pais='Argentina'):
    url_portafolio = f'https://api.invertironline.com/api/v2/Asesores/Portafolio/{id_cliente}/{pais}'
    encabezados = obtener_encabezado_autorizacion(token_portador)
    try:
        respuesta = requests.get(url_portafolio, headers=encabezados)
        # Eliminar mensajes de interfaz innecesarios
        # st.info(f"üîç Solicitando portafolio para cliente {id_cliente}")
        # st.info(f"üì° URL: {url_portafolio}")
        # st.info(f"üìä Status Code: {respuesta.status_code}")
        
        if respuesta.status_code == 200:
            portafolio_data = respuesta.json()
            # st.success(f"‚úÖ Portafolio obtenido exitosamente")
            # st.info(f"üìã Estructura de portafolio: {type(portafolio_data)}")
            # if isinstance(portafolio_data, dict):
            #     st.info(f"üîë Claves disponibles: {list(portafolio_data.keys())}")
            return portafolio_data
        elif respuesta.status_code == 404:
            st.warning(f"‚ö†Ô∏è Cliente {id_cliente} no encontrado o sin portafolio")
            return None
        elif respuesta.status_code == 401:
            st.error("üîê Token de autorizaci√≥n expirado o inv√°lido")
            return None
        else:
            st.error(f'‚ùå Error al obtener portafolio: {respuesta.status_code}')
            st.error(f'üìÑ Respuesta: {respuesta.text}')
            return None
    except Exception as e:
        st.error(f'üí• Error de conexi√≥n al obtener portafolio: {str(e)}')
        return None

def obtener_cotizacion_mep(token_portador, simbolo, id_plazo_compra, id_plazo_venta):
    url_cotizacion_mep = 'https://api.invertironline.com/api/v2/Cotizaciones/MEP'
    encabezados = obtener_encabezado_autorizacion(token_portador)
    datos = {
        "simbolo": simbolo,
        "idPlazoOperatoriaCompra": id_plazo_compra,
        "idPlazoOperatoriaVenta": id_plazo_venta
    }
    try:
        respuesta = requests.post(url_cotizacion_mep, headers=encabezados, json=datos)
        if respuesta.status_code == 200:
            return respuesta.json()
        else:
            return None
    except Exception as e:
        st.error(f'Error al obtener cotizaci√≥n MEP: {str(e)}')
        return None

def obtener_tasas_caucion(token_portador, instrumento="Cauciones", panel="Todas", pais="Argentina"):
    url = f"https://api.invertironline.com/api/v2/Cotizaciones/{instrumento}/{panel}/{pais}"
    headers = {
        "Authorization": f"Bearer {token_portador}"
    }
    try:
        response = requests.get(url, headers=headers)
        if response.status_code == 200:
            return response.json()
        else:
            return None
    except Exception as e:
        st.error(f'Error al obtener tasas de cauci√≥n: {str(e)}')
        return None

def obtener_cotizacion_actual(token_portador, mercado, simbolo):
    """
    Obtiene la cotizaci√≥n actual de un t√≠tulo desde la API de IOL.
    """
    url = f"https://api.invertironline.com/api/v2/{mercado}/Titulos/{simbolo}/Cotizacion"
    headers = obtener_encabezado_autorizacion(token_portador)
    
    try:
        response = requests.get(url, headers=headers)
        if response.status_code == 200:
            return response.json()
        else:
            st.error(f"Error al obtener la cotizaci√≥n actual para {simbolo}: {response.status_code}")
            return None
    except Exception as e:
        st.error(f'Error al obtener cotizaci√≥n actual: {str(e)}')
        return None

def parse_datetime_flexible(datetime_string):
    """
    Parse datetime strings with flexible format handling
    """
    if not datetime_string:
        return None
    
    # Common datetime formats from IOL API
    formats_to_try = [
        "%Y-%m-%dT%H:%M:%S.%f",  # With microseconds
        "%Y-%m-%dT%H:%M:%S",     # Without microseconds
        "%Y-%m-%d %H:%M:%S.%f",  # Space separator with microseconds
        "%Y-%m-%d %H:%M:%S",     # Space separator without microseconds
        "ISO8601",               # Let pandas infer ISO format
        "mixed"                  # Let pandas infer mixed formats
    ]
    
    for fmt in formats_to_try:
        try:
            if fmt == "ISO8601":
                return pd.to_datetime(datetime_string, format='ISO8601')
            elif fmt == "mixed":
                return pd.to_datetime(datetime_string, format='mixed')
            else:
                return pd.to_datetime(datetime_string, format=fmt)
        except Exception:
            continue

    # Final fallback - let pandas infer automatically
    try:
        return pd.to_datetime(datetime_string, infer_datetime_format=True)
    except Exception:
        return None

def obtener_serie_historica_iol(token_portador, mercado, simbolo, fecha_desde, fecha_hasta, ajustada="ajustada"):
    """
    Obtiene la serie hist√≥rica de precios de un t√≠tulo desde la API de IOL.
    Actualizada para manejar correctamente la estructura de respuesta de la API.
    """
    # Determinar endpoint seg√∫n tipo de instrumento
    if mercado == "Opciones":
        url = f"https://api.invertironline.com/api/v2/Opciones/{simbolo}/Cotizacion/seriehistorica/{fecha_desde}/{fecha_hasta}/{ajustada}"
    elif mercado == "FCI":
        url = f"https://api.invertironline.com/api/v2/FCI/{simbolo}/Cotizacion/seriehistorica/{fecha_desde}/{fecha_hasta}/{ajustada}"
    else:
        url = f"https://api.invertironline.com/api/v2/{mercado}/Titulos/{simbolo}/Cotizacion/seriehistorica/{fecha_desde}/{fecha_hasta}/{ajustada}"
    
    headers = {
        'Accept': 'application/json',
        'Authorization': f'Bearer {token_portador}',
        'Content-Type': 'application/json'
    }
    
    try:
        response = requests.get(url, headers=headers, timeout=30)
        
        if response.status_code == 200:
            data = response.json()
            if not data:
                return None
            
            precios = []
            fechas = []
            
            for item in data:
                try:
                    # Usar ultimoPrecio como precio principal seg√∫n la documentaci√≥n
                    precio = item.get('ultimoPrecio')
                    
                    # Si ultimoPrecio es 0 o None, intentar otros campos
                    if not precio or precio == 0:
                        precio = item.get('cierreAnterior') or item.get('precioPromedio') or item.get('apertura')
                    
                    fecha_str = item.get('fechaHora')
                    
                    if precio is not None and precio > 0 and fecha_str:
                        fecha_parsed = parse_datetime_flexible(fecha_str)
                        if fecha_parsed is not None:
                            precios.append(precio)
                            fechas.append(fecha_parsed)
                            
                except Exception as e:
                    # Log individual item errors but continue processing
                    continue
            
            if precios and fechas:
                # Crear serie ordenada por fecha
                serie = pd.Series(precios, index=fechas)
                serie = serie.sort_index()  # Asegurar orden cronol√≥gico
                
                # Eliminar duplicados manteniendo el √∫ltimo valor
                serie = serie[~serie.index.duplicated(keep='last')]
                
                return serie
            else:
                return None
                
        elif response.status_code == 401:
            # Token expirado o inv√°lido
            st.warning(f"‚ö†Ô∏è Token de autorizaci√≥n inv√°lido para {simbolo}")
            return None
            
        elif response.status_code == 404:
            # S√≠mbolo no encontrado en este mercado
            return None
            
        elif response.status_code == 400:
            # Par√°metros inv√°lidos
            st.warning(f"‚ö†Ô∏è Par√°metros inv√°lidos para {simbolo} en {mercado}")
            return None
            
        elif response.status_code == 500:
            # Error del servidor - silencioso para no interrumpir el flujo
            return None
            
        else:
            # Otros errores HTTP
            return None
            
    except requests.exceptions.Timeout:
        # Timeout - silencioso
        return None
    except requests.exceptions.ConnectionError:
        # Error de conexi√≥n - silencioso
        return None
    except Exception as e:
        # Error general - silencioso para no interrumpir el an√°lisis
        return None

def obtener_datos_alternativos_yfinance(simbolo, fecha_desde, fecha_hasta):
    """
    Fallback usando yfinance para s√≠mbolos que no est√©n disponibles en IOL
    """
    try:
        # Mapear s√≠mbolos argentinos a Yahoo Finance si es posible
        simbolo_yf = simbolo
        
        # Agregar sufijos comunes para acciones argentinas
        sufijos_ar = ['.BA', '.AR']
        
        for sufijo in sufijos_ar:
            try:
                ticker = yf.Ticker(simbolo + sufijo)
                data = ticker.history(start=fecha_desde, end=fecha_hasta)
                if not data.empty and len(data) > 10:
                    # Usar precio de cierre
                    return data['Close']
            except:
                continue
        
        # Intentar sin sufijo
        try:
            ticker = yf.Ticker(simbolo)
            data = ticker.history(start=fecha_desde, end=fecha_hasta)
            if not data.empty and len(data) > 10:
                return data['Close']
        except:
            pass
            
        return None
    except Exception:
        return None

def get_historical_data_for_optimization(token_portador, simbolos, fecha_desde, fecha_hasta):
    """
    Obtiene datos hist√≥ricos para optimizaci√≥n de portafolio usando SOLO la funci√≥n obtener_serie_historica_iol
    (con fallback a yfinance solo si falla), para todos los instrumentos: acciones, bonos, FCI, opciones, etc.
    Alinea las fechas solo si hay al menos 2 activos con fechas comunes, si no, intenta devolver los datos disponibles.
    """
    try:
        df_precios = pd.DataFrame()
        simbolos_exitosos = []
        simbolos_fallidos = []
        detalles_errores = {}

        fecha_desde_str = fecha_desde.strftime('%Y-%m-%d')
        fecha_hasta_str = fecha_hasta.strftime('%Y-%m-%d')

        st.info(f"üîç Buscando datos hist√≥ricos desde {fecha_desde_str} hasta {fecha_hasta_str}")

        progress_bar = st.progress(0)
        total_simbolos = len(simbolos)

        for idx, simbolo in enumerate(simbolos):
            progress_bar.progress((idx + 1) / total_simbolos, text=f"Procesando {simbolo}...")

            serie_obtenida = False
            simbolo_upper = simbolo.upper()

            # Determinar mercados seg√∫n el tipo de instrumento
            if simbolo_upper == "ADCGLOA":
                mercados = ['FCI']
            elif simbolo_upper.startswith("AE") or simbolo_upper.endswith("D") or simbolo_upper.endswith("C") or simbolo_upper.endswith("O"):
                mercados = ['bCBA']
            elif simbolo_upper.endswith("48") or simbolo_upper.endswith("30") or simbolo_upper.endswith("29"):
                mercados = ['bCBA']
            elif simbolo_upper.startswith("MERV") or simbolo_upper.startswith("OPC"):
                mercados = ['Opciones']
            else:
                mercados = ['bCBA', 'nYSE', 'nASDAQ', 'rOFEX']

            # Intentar obtener datos de cada mercado usando SIEMPRE obtener_serie_historica_iol
            for mercado in mercados:
                try:
                    simbolo_consulta = simbolo
                    # Buscar clase D solo para bonos en bCBA
                    if mercado == 'bCBA' and (simbolo_upper.endswith("D") or simbolo_upper.endswith("C") or simbolo_upper.endswith("O") or simbolo_upper.startswith("AE")):
                        clase_d = obtener_clase_d(simbolo, mercado, token_portador)
                        if clase_d:
                            simbolo_consulta = clase_d

                    serie = obtener_serie_historica_iol(
                        token_portador, mercado, simbolo_consulta,
                        fecha_desde_str, fecha_hasta_str
                    )

                    if serie is not None and len(serie) > 10:
                        # Verificar que la serie tenga valores v√°lidos y variaci√≥n
                        serie_clean = serie.dropna()
                        if len(serie_clean) > 10 and serie_clean.nunique() > 1 and serie_clean.std() > 0:
                            df_precios[simbolo] = serie_clean
                            simbolos_exitosos.append(simbolo)
                            serie_obtenida = True
                            st.success(f"‚úÖ {simbolo} ({mercado}): {len(serie_clean)} puntos de datos")
                            break
                except Exception as e:
                    detalles_errores[f"{simbolo}_{mercado}"] = str(e)
                    continue

            # Fallback a yfinance solo si no se pudo obtener de IOL
            if not serie_obtenida:
                try:
                    serie_yf = obtener_datos_alternativos_yfinance(
                        simbolo, fecha_desde, fecha_hasta
                    )
                    if serie_yf is not None and len(serie_yf) > 10:
                        serie_yf_clean = serie_yf.dropna()
                        if len(serie_yf_clean) > 10 and serie_yf_clean.nunique() > 1 and serie_yf_clean.std() > 0:
                            df_precios[simbolo] = serie_yf_clean
                            simbolos_exitosos.append(simbolo)
                            serie_obtenida = True
                            st.info(f"‚ÑπÔ∏è {simbolo} (Yahoo Finance): {len(serie_yf_clean)} puntos de datos")
                except Exception as e:
                    detalles_errores[f"{simbolo}_yfinance"] = str(e)

            if not serie_obtenida:
                simbolos_fallidos.append(simbolo)
                st.warning(f"‚ö†Ô∏è No se pudieron obtener datos para {simbolo}")

        progress_bar.empty()

        if simbolos_exitosos:
            st.success(f"‚úÖ Datos obtenidos para {len(simbolos_exitosos)} activos")
            with st.expander("üìã Ver activos exitosos"):
                for simbolo in simbolos_exitosos:
                    if simbolo in df_precios.columns:
                        serie = df_precios[simbolo].dropna()
                        if len(serie) > 0:
                            datos_info = f"{simbolo}: {len(serie)} puntos, rango: {serie.min():.2f} - {serie.max():.2f}"
                            st.text(datos_info)

        if simbolos_fallidos:
            st.warning(f"‚ö†Ô∏è No se pudieron obtener datos para {len(simbolos_fallidos)} activos")
            with st.expander("‚ùå Ver activos fallidos y errores"):
                for simbolo in simbolos_fallidos:
                    st.text(f"‚Ä¢ {simbolo}")
                if detalles_errores:
                    st.markdown("**Detalles de errores:**")
                    for key, error in detalles_errores.items():
                        st.text(f"{key}: {error}")

        if len(simbolos_exitosos) < 2:
            if len(simbolos_exitosos) == 1:
                st.error("‚ùå Se necesitan al menos 2 activos con datos hist√≥ricos v√°lidos para el an√°lisis.")
            else:
                st.error("‚ùå No se pudieron obtener datos hist√≥ricos para ning√∫n activo.")
            st.markdown("#### üí° Sugerencias para resolver el problema:")
            st.markdown("""
            1. **Verificar conectividad**: Aseg√∫rese de que su conexi√≥n a IOL est√© activa
            2. **Revisar s√≠mbolos**: Algunos s√≠mbolos pueden haber cambiado o no estar disponibles
            3. **Ajustar fechas**: Pruebe con un rango de fechas m√°s amplio o diferente
            4. **Verificar permisos**: Aseg√∫rese de tener permisos para acceder a datos hist√≥ricos
            """)
            return None, None, None

        if len(simbolos_exitosos) < len(simbolos):
            st.info(f"‚ÑπÔ∏è Continuando an√°lisis con {len(simbolos_exitosos)} de {len(simbolos)} activos disponibles.")

        st.info(f"üìä Alineando datos de {len(df_precios.columns)} activos...")

        if df_precios.empty:
            st.error("‚ùå DataFrame de precios est√° vac√≠o")
            return None, None, None

        # Limpiar datos y alinear fechas
        try:
            # Paso 1: Asegurar que todas las series tengan al menos 30 puntos
            series_validas = {}
            for col in df_precios.columns:
                serie = df_precios[col].dropna()
                if len(serie) >= 30 and serie.std() > 0:
                    series_validas[col] = serie
                else:
                    st.warning(f"‚ö†Ô∏è Descartando {col}: insuficientes datos v√°lidos ({len(serie)} puntos)")
            
            if len(series_validas) < 2:
                st.error("‚ùå No hay suficientes activos con datos v√°lidos despu√©s del filtrado")
                return None, None, None
            
            # Paso 2: Crear DataFrame con series v√°lidas
            df_precios_limpio = pd.DataFrame(series_validas)
            
            # Paso 3: Buscar fechas comunes
            fechas_comunes = None
            for col in df_precios_limpio.columns:
                fechas_serie = set(df_precios_limpio[col].dropna().index)
                if fechas_comunes is None:
                    fechas_comunes = fechas_serie
                else:
                    fechas_comunes = fechas_comunes.intersection(fechas_serie)
            
            # Paso 4: Decidir estrategia de alineaci√≥n
            if len(fechas_comunes) >= 30:
                # Usar solo fechas comunes
                fechas_comunes_sorted = sorted(list(fechas_comunes))
                df_aligned = df_precios_limpio.loc[fechas_comunes_sorted].dropna()
                st.info(f"‚úÖ Usando {len(fechas_comunes)} fechas comunes")
            else:
                # Estrategia de interpolaci√≥n y rellenado
                st.warning(f"‚ö†Ô∏è Solo {len(fechas_comunes)} fechas comunes. Aplicando interpolaci√≥n...")
                
                # Reindexar a fechas completas del rango
                fecha_completa = pd.date_range(start=fecha_desde, end=fecha_hasta, freq='D')
                df_reindexed = df_precios_limpio.reindex(fecha_completa)
                
                # Aplicar forward fill y backward fill
                df_filled = df_reindexed.fillna(method='ffill').fillna(method='bfill')
                
                # Quitar fines de semana y d√≠as sin datos en ninguna serie
                df_aligned = df_filled.dropna()
                
                if len(df_aligned) < 30:
                    st.error("‚ùå No hay suficientes datos despu√©s de la alineaci√≥n")
                    return None, None, None
                
                st.info(f"‚úÖ Datos interpolados: {len(df_aligned)} observaciones")
            
            # Paso 5: Calcular retornos
            returns = df_aligned.pct_change().dropna()
            
            # Verificar que los retornos sean v√°lidos
            if returns.empty or len(returns) < 20:
                st.error("‚ùå No hay suficientes retornos v√°lidos para el an√°lisis")
                return None, None, None
            
            # Verificar que no haya retornos constantes
            returns_std = returns.std()
            columnas_constantes = returns_std[returns_std == 0].index.tolist()
            
            if len(columnas_constantes) > 0:
                st.warning(f"‚ö†Ô∏è Removiendo activos con retornos constantes: {columnas_constantes}")
                returns = returns.drop(columns=columnas_constantes)
                df_aligned = df_aligned.drop(columns=columnas_constantes)
            
            if len(returns.columns) < 2:
                st.error("‚ùå Despu√©s de filtrar, no quedan suficientes activos para an√°lisis")
                return None, None, None
            
            # Paso 6: Calcular estad√≠sticas finales
            mean_returns = returns.mean() * 252  # Anualizar
            cov_matrix = returns.cov() * 252     # Anualizar
            
            # Verificar que la matriz de covarianza sea v√°lida
            if np.any(np.isnan(cov_matrix.values)) or np.any(np.isinf(cov_matrix.values)):
                st.error("‚ùå Matriz de covarianza contiene valores inv√°lidos")
                return None, None, None
            
            # Mostrar estad√≠sticas finales
            st.info(f"üìä Datos finales: {len(returns.columns)} activos, {len(returns)} observaciones de retornos")
            
            with st.expander("üîç Debug - Estad√≠sticas de retornos"):
                st.write("**Retornos medios anualizados:**")
                for col in mean_returns.index:
                    st.text(f"{col}: {mean_returns[col]:.2%}")
                
                st.write("**Volatilidades anualizadas:**")
                vol_annual = returns.std() * np.sqrt(252)
                for col in vol_annual.index:
                    st.text(f"{col}: {vol_annual[col]:.2%}")
            
            return mean_returns, cov_matrix, df_aligned
            
        except Exception as e:
            st.error(f"‚ùå Error en procesamiento de datos: {str(e)}")
            return None, None, None
        
    except Exception as e:
        st.error(f"‚ùå Error cr√≠tico obteniendo datos hist√≥ricos: {str(e)}")
        return None, None, None

def obtener_serie_historica(simbolo, mercado, fecha_desde, fecha_hasta, ajustada, bearer_token):
    """
    Obtiene la serie hist√≥rica de precios para un s√≠mbolo y mercado espec√≠fico.
    Usa el mapeo de mercados de IOL y busca autom√°ticamente la clase 'D' si existe.
    """
    # Mapear nombres de mercados a los correctos de IOL
    mercados_mapping = {
        'BCBA': 'bCBA',
        'NYSE': 'nYSE',
        'NASDAQ': 'nASDAQ',
        'ROFEX': 'rOFEX',
        'Merval': 'bCBA'
    }
    mercado_correcto = mercados_mapping.get(mercado, mercado)
    # Buscar clase D si es bono
    clase_d = obtener_clase_d(simbolo, mercado_correcto, bearer_token)
    simbolo_final = clase_d if clase_d else simbolo
    url = f"https://api.invertironline.com/api/v2/{mercado_correcto}/Titulos/{simbolo_final}/Cotizacion/seriehistorica/{fecha_desde}/{fecha_hasta}/{ajustada}"
    headers = {
        'Accept': 'application/json',
        'Authorization': f'Bearer {bearer_token}'
    }
    response = requests.get(url, headers=headers)
    if response.status_code == 200:
        return response.json()
    else:
        print(f"Error en la solicitud de serie hist√≥rica para {simbolo_final} en {mercado_correcto}: {response.status_code}")
        print(response.text)
        return None

def obtener_clase_d(simbolo, mercado, bearer_token):
    """
    Busca autom√°ticamente la clase 'D' de un bono dado su s√≠mbolo y mercado.
    Devuelve el s√≠mbolo de la clase 'D' si existe, si no, devuelve None.
    """
    # Mapear nombres de mercados a los correctos de IOL
    mercados_mapping = {
        'BCBA': 'bCBA',
        'NYSE': 'nYSE',
        'NASDAQ': 'nASDAQ',
        'ROFEX': 'rOFEX',
        'Merval': 'bCBA'
    }
    mercado_correcto = mercados_mapping.get(mercado, mercado)
    url = f"https://api.invertironline.com/api/v2/{mercado_correcto}/Titulos/{simbolo}/Clases"
    headers = {
        'Accept': 'application/json',
        'Authorization': f'Bearer {bearer_token}'
    }
    response = requests.get(url, headers=headers)
    if response.status_code == 200:
        clases = response.json()
        for clase in clases:
            if clase.get('simbolo', '').endswith('D'):
                return clase['simbolo']
        return None
    else:
        print(f"Error al buscar clases para {simbolo} en {mercado_correcto}: {response.status_code}")
        print(response.text)
        return None

# --- Portfolio Optimization Functions ---
def calculate_portfolio_metrics(returns, weights):
    """
    Calcula m√©tricas b√°sicas de un portafolio
    """
    portfolio_return = np.sum(returns.mean() * weights) * 252
    portfolio_std = np.sqrt(np.dot(weights.T, np.dot(returns.cov() * 252, weights)))
    sharpe_ratio = portfolio_return / portfolio_std if portfolio_std > 0 else 0
    
    return portfolio_return, portfolio_std, sharpe_ratio

def optimize_portfolio(returns, risk_free_rate=0.0, target_return=None):
    """
    Optimiza un portafolio usando teor√≠a moderna de portafolio
    """
    try:
        from scipy.optimize import minimize
        
        n_assets = len(returns.columns)
        
        # Funci√≥n objetivo para maximizar el ratio de Sharpe
        def negative_sharpe(weights):
            portfolio_return = np.sum(returns.mean() * weights) * 252
            portfolio_std = np.sqrt(np.dot(weights.T, np.dot(returns.cov() * 252, weights)))
            if portfolio_std == 0:
                return -np.inf
            sharpe_ratio = (portfolio_return - risk_free_rate) / portfolio_std
            return -sharpe_ratio
        
        # Restricciones
        constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})
        bounds = tuple((0, 1) for _ in range(n_assets))
        
        # Pesos iniciales igualmente distribuidos
        initial_guess = n_assets * [1. / n_assets]
        
        # Optimizaci√≥n
        result = minimize(negative_sharpe, initial_guess, method='SLSQP',
                         bounds=bounds, constraints=constraints)
        
        if result.success:
            return result.x
        else:
            st.warning("La optimizaci√≥n no convergi√≥. Usando pesos iguales.")
            return np.array(initial_guess)
            
    except ImportError:
        st.warning("scipy no disponible. Usando pesos iguales.")
        return np.array([1/n_assets] * n_assets)
    except Exception as e:
        st.warning(f"Error en optimizaci√≥n: {str(e)}. Usando pesos iguales.")
        return np.array([1/n_assets] * n_assets)

def calcular_metricas_portafolio(activos_data, valor_total):
    """
    Calcula m√©tricas comprehensivas del portafolio incluyendo P&L, quantiles y probabilidades
    """
    try:
        # Calcular estad√≠sticas b√°sicas
        valores = [activo['Valuaci√≥n'] for activo in activos_data if activo['Valuaci√≥n'] > 0]
        
        if not valores:
            return None
        
        # Convertir a numpy array para c√°lculos
        valores_array = np.array(valores)
        
        # Estad√≠sticas b√°sicas
        media = np.mean(valores_array)
        mediana = np.median(valores_array)
        std_dev = np.std(valores_array)
        var_95 = np.percentile(valores_array, 5)  # VaR al 5%
        var_99 = np.percentile(valores_array, 1)  # VaR al 1%
        
        # Quantiles
        q25 = np.percentile(valores_array, 25)
        q50 = np.percentile(valores_array, 50)  # Mediana
        q75 = np.percentile(valores_array, 75)
        q90 = np.percentile(valores_array, 90)
        q95 = np.percentile(valores_array, 95)
        
        # Calcular concentraci√≥n del portafolio
        pesos = valores_array / valor_total
        concentracion = np.sum(pesos ** 2)  # √çndice de Herfindahl
        
        # Simular retornos esperados (usando distribuci√≥n normal)
        # Asumiendo retorno anual promedio del 8% con volatilidad del 20%
        retorno_esperado_anual = 0.08
        volatilidad_anual = 0.20
        
        # Calcular m√©tricas en t√©rminos monetarios
        retorno_esperado_pesos = valor_total * retorno_esperado_anual
        riesgo_anual_pesos = valor_total * volatilidad_anual
        
        # Simulaci√≥n Monte Carlo simple para P&L esperado
        np.random.seed(42)
        num_simulaciones = 1000
        retornos_simulados = np.random.normal(retorno_esperado_anual, volatilidad_anual, num_simulaciones)
        pl_simulado = valor_total * retornos_simulados
        
        # Probabilidades
        prob_ganancia = np.sum(pl_simulado > 0) / num_simulaciones
        prob_perdida = np.sum(pl_simulado < 0) / num_simulaciones
        prob_perdida_mayor_10 = np.sum(pl_simulado < -valor_total * 0.10) / num_simulaciones
        prob_ganancia_mayor_10 = np.sum(pl_simulado > valor_total * 0.10) / num_simulaciones
        
        return {
            'valor_total': valor_total,
            'media_activo': media,
            'mediana_activo': mediana,
            'std_dev_activo': std_dev,
            'var_95': var_95,
            'var_99': var_99,
            'quantiles': {
                'q25': q25,
                'q50': q50,
                'q75': q75,
                'q90': q90,
                'q95': q95
            },
            'concentracion': concentracion,
            'retorno_esperado_anual': retorno_esperado_pesos,
            'riesgo_anual': riesgo_anual_pesos,
            'pl_esperado_min': np.min(pl_simulado),
            'pl_esperado_max': np.max(pl_simulado),
            'pl_esperado_medio': np.mean(pl_simulado),
            'pl_percentil_5': np.percentile(pl_simulado, 5),
            'pl_percentil_95': np.percentile(pl_simulado, 95),
            'probabilidades': {
                'ganancia': prob_ganancia,
                'perdida': prob_perdida,
                'perdida_mayor_10': prob_perdida_mayor_10,
                'ganancia_mayor_10': prob_ganancia_mayor_10
            }
        }
    except Exception as e:
        st.error(f"Error calculando m√©tricas del portafolio: {str(e)}")
        return None

def mostrar_resumen_portafolio(portafolio):
    """
    Muestra un resumen comprehensivo del portafolio con valuaci√≥n corregida y m√©tricas avanzadas
    """
    st.markdown("### üìà Resumen del Portafolio")
    
    activos = portafolio.get('activos', [])
    
    # Preparar datos para an√°lisis con mejor extracci√≥n de valuaci√≥n
    datos_activos = []
    valor_total = 0
    
    for activo in activos:
        try:
            titulo = activo.get('titulo', {})
            simbolo = titulo.get('simbolo', 'N/A')
            descripcion = titulo.get('descripcion', 'Sin descripci√≥n')
            tipo = titulo.get('tipo', 'N/A')
            cantidad = activo.get('cantidad', 0)
            
            # Mejorar extracci√≥n de valuaci√≥n con m√°s campos posibles
            valuacion = 0
            
            # Campos de valuaci√≥n en orden de preferencia (m√°s espec√≠ficos primero)
            campos_valuacion = [
                'valuacionEnMonedaOriginal',
                'valuacionActual',
                'valorNominalEnMonedaOriginal', 
                'valorNominal',
                'valuacionDolar',
                'valuacion',
                'valorActual',
                'montoInvertido',
                'valorMercado',
                'valorTotal',
                'importe'
            ]
            
            for campo in campos_valuacion:
                if campo in activo and activo[campo] is not None:
                    try:
                        val = float(activo[campo])
                        if val > 0:  # Solo usar valores positivos
                            valuacion = val
                            break
                    except (ValueError, TypeError):
                        continue
            
            # Si no se encuentra valuaci√≥n directa, intentar calcular
            if valuacion == 0 and cantidad:
                # Buscar precio unitario
                precio_unitario = 0
                campos_precio = [
                    'precioPromedio',
                    'precioCompra',
                    'precioActual',
                    'precio',
                    'precioUnitario',
                    'ultimoPrecio',
                    'cotizacion'
                ]
                
                # Buscar en activo
                for campo in campos_precio:
                    if campo in activo and activo[campo] is not None:
                        try:
                            precio = float(activo[campo])
                            if precio > 0:
                                precio_unitario = precio
                                break
                        except (ValueError, TypeError):
                            continue
                
                # Buscar en t√≠tulo si no se encontr√≥ en activo
                if precio_unitario == 0:
                    for campo in campos_precio:
                        if campo in titulo and titulo[campo] is not None:
                            try:
                                precio = float(titulo[campo])
                                if precio > 0:
                                    precio_unitario = precio
                                    break
                            except (ValueError, TypeError):
                                continue
                
                # Calcular valuaci√≥n si encontramos precio
                if precio_unitario > 0:
                    try:
                        cantidad_num = float(cantidad)
                        valuacion = cantidad_num * precio_unitario
                    except (ValueError, TypeError):
                        pass
            
            datos_activos.append({
                'S√≠mbolo': simbolo,
                'Descripci√≥n': descripcion,
                'Tipo': tipo,
                'Cantidad': cantidad,
                'Valuaci√≥n': valuacion,
                'Datos_Raw': activo  # Para debug
            })
            
            valor_total += valuacion;
            
        except Exception as e:
            st.warning(f"Error procesando activo: {str(e)}")
            continue
    
    # Mostrar informaci√≥n de debug para verificar el c√°lculo
    with st.expander("üîç Debug - Verificaci√≥n de Valuaciones"):
        st.write("**Valuaciones individuales por activo:**")
        for i, activo_data in enumerate(datos_activos):
            st.write(f"{activo_data['S√≠mbolo']}: ${activo_data['Valuaci√≥n']:,.2f}")
        st.write(f"**Suma total calculada: ${valor_total:,.2f}**")
        
        # Verificar si el valor parece estar en una escala incorrecta
        if valor_total > 100000:
            st.warning("‚ö†Ô∏è El valor total parece ser muy alto. Verificando posibles errores de escala...")
            # Intentar detectar si los valores est√°n multiplicados por 10
            valor_corregido = valor_total / 10
            st.info(f"üí° Valor corregido (√∑10): ${valor_corregido:,.2f}")
            
            # Preguntar al usuario si quiere usar el valor corregido
            if st.button("üîß Usar valor corregido"):
                valor_total = valor_corregido
                # Corregir tambi√©n las valuaciones individuales
                for activo_data in datos_activos:
                    activo_data['Valuaci√≥n'] = activo_data['Valuaci√≥n'] / 10
                st.success("‚úÖ Valores corregidos aplicados")
                st.rerun()
    
    if datos_activos:
        df_activos = pd.DataFrame(datos_activos)
        
        # Calcular m√©tricas comprehensivas del portafolio
        metricas = calcular_metricas_portafolio(datos_activos, valor_total)
        
        # === 1. INFORMACI√ìN B√ÅSICA DEL PORTAFOLIO ===
        st.markdown("#### üìä Informaci√≥n General")
        col1, col2, col3, col4 = st.columns(4)
        col1.metric("Total de Activos", len(datos_activos))
        col2.metric("S√≠mbolos √önicos", df_activos['S√≠mbolo'].nunique())
        col3.metric("Tipos de Activos", df_activos['Tipo'].nunique())
        
        # Mostrar el valor total con formato correcto y verificaci√≥n
        valor_display = f"${valor_total:,.2f}"
        if valor_total > 500000:  # Si parece demasiado alto
            st.warning("‚ö†Ô∏è Verificar: el valor total parece alto")
        col4.metric("Valor Total del Portafolio", valor_display)
        
        # === 2. M√âTRICAS DE RIESGO ACTUALES ===
        if metricas:
            st.markdown("#### ‚ö†Ô∏è An√°lisis de Riesgo")
            col1, col2, col3, col4 = st.columns(4)
            
            col1.metric(
                "Concentraci√≥n del Portafolio", 
                f"{metricas['concentracion']:.3f}",
                help="√çndice de Herfindahl: 0=perfectamente diversificado, 1=completamente concentrado"
            )
            col2.metric(
                "VaR 95% (Valor en Riesgo)", 
                f"${metricas['var_95']:,.0f}",
                help="Valor m√≠nimo del activo m√°s peque√±o en el 95% de los casos"
            )
            col3.metric(
                "Volatilidad Estimada Anual", 
                f"${metricas['riesgo_anual']:,.0f}",
                help="Riesgo anual estimado basado en 20% de volatilidad"
            )
            
            # Indicador visual de concentraci√≥n
            concentracion_status = "üü¢ Diversificado" if metricas['concentracion'] < 0.25 else "üü° Moderadamente Concentrado" if metricas['concentracion'] < 0.5 else "üî¥ Altamente Concentrado"
            col4.metric("Estado de Diversificaci√≥n", concentracion_status)
        
        # === 3. PROYECCIONES DE RENDIMIENTO ===
        if metricas:
            st.markdown("#### üìà Proyecciones de Rendimiento (Pr√≥ximos 12 meses)")
            
            col1, col2, col3 = st.columns(3)
            col1.metric(
                "Retorno Esperado", 
                f"${metricas['retorno_esperado_anual']:,.0f}",
                delta=f"{(metricas['retorno_esperado_anual']/valor_total*100):.1f}%",
                help="Retorno esperado promedio basado en 8% anual"
            )
            col2.metric(
                "Escenario Optimista (95%)", 
                f"${metricas['pl_percentil_95']:,.0f}",
                delta=f"+{(metricas['pl_percentil_95']/valor_total*100):.1f}%",
                help="Ganancia esperada en el mejor 5% de los casos"
            )
            col3.metric(
                "Escenario Pesimista (5%)", 
                f"${metricas['pl_percentil_5']:,.0f}",
                delta=f"{(metricas['pl_percentil_5']/valor_total*100):.1f}%",
                help="P√©rdida m√°xima esperada en el peor 5% de los casos"
            )
        
        # === 4. PROBABILIDADES DE ESCENARIOS ===
        if metricas:
            st.markdown("#### üéØ Probabilidades de Escenarios")
            
            col1, col2, col3, col4 = st.columns(4)
            probs = metricas['probabilidades']
            
            col1.metric(
                "Probabilidad de Ganancia", 
                f"{probs['ganancia']*100:.1f}%",
                help="Probabilidad de obtener rendimientos positivos"
            )
            col2.metric(
                "Probabilidad de P√©rdida", 
                f"{probs['perdida']*100:.1f}%",
                help="Probabilidad de obtener rendimientos negativos"
            )
            col3.metric(
                "Prob. Ganancia > 10%", 
                f"{probs['ganancia_mayor_10']*100:.1f}%",
                help="Probabilidad de obtener m√°s del 10% de ganancia"
            )
            col4.metric(
                "Prob. P√©rdida > 10%", 
                f"{probs['perdida_mayor_10']*100:.1f}%",
                help="Probabilidad de perder m√°s del 10%"
            )
        
        # === 5. DISTRIBUCI√ìN DETALLADA DE ACTIVOS ===
        if metricas:
            st.markdown("#### üìä Distribuci√≥n Estad√≠stica de Valores por Activo")
            
            col1, col2, col3, col4, col5 = st.columns(5)
            quantiles = metricas['quantiles']
            
            col1.metric(
                "Valor M√≠nimo (Q25)", 
                f"${quantiles['q25']:,.0f}",
                help="25% de los activos valen menos que este monto"
            )
            col2.metric(
                "Valor Mediano (Q50)", 
                f"${quantiles['q50']:,.0f}",
                help="Valor medio de los activos del portafolio"
            )
            col3.metric(
                "Tercer Cuartil (Q75)", 
                f"${quantiles['q75']:,.0f}",
                help="75% de los activos valen menos que este monto"
            )
            col4.metric(
                "Percentil 90", 
                f"${quantiles['q90']:,.0f}",
                help="90% de los activos valen menos que este monto"
            )
            col5.metric(
                "Valor M√°ximo (Q95)", 
                f"${quantiles['q95']:,.0f}",
                help="Solo el 5% de los activos supera este valor"
            )
        
        # Informaci√≥n de debug mejorada
        with st.expander("üîç Informaci√≥n de Debug - Estructura del Portafolio"):
            st.markdown("**Campos disponibles en los activos:**")
            if activos:
                campos_encontrados = set()
                for activo in activos[:3]:
                    campos_encontrados.update(activo.keys())
                    if 'titulo' in activo and isinstance(activo['titulo'], dict):
                        titulo_campos = [f"titulo.{k}" for k in activo['titulo'].keys()]
                        campos_encontrados.update(titulo_campos)
                
                st.code(sorted(list(campos_encontrados)))
                
                st.markdown("**Muestra de datos de activo:**")
                st.json(activos[0] if activos else {})
        
        # Gr√°ficos de distribuci√≥n
        if valor_total > 0:
            # Gr√°fico de distribuci√≥n por tipo
            if 'Tipo' in df_activos.columns and df_activos['Valuaci√≥n'].sum() > 0:
                tipo_stats = df_activos.groupby('Tipo').agg({
                    'Valuaci√≥n': ['sum', 'count', 'mean']
                }).round(2)
                tipo_stats.columns = ['Valor_Total', 'Cantidad', 'Valor_Promedio']
                tipo_stats = tipo_stats.reset_index()
                
                col1, col2 = st.columns(2)
                
                with col1:
                    # Pie chart por valor
                    fig_pie = go.Figure(data=[go.Pie(
                        labels=tipo_stats['Tipo'],
                        values=tipo_stats['Valor_Total'],
                        textinfo='label+percent+value',
                        texttemplate='%{label}<br>%{percent}<br>$%{value:,.0f}',
                    )])
                    fig_pie.update_layout(title="Distribuci√≥n por Valor", height=400)
                    st.plotly_chart(fig_pie, use_container_width=True)
                
                with col2:
                    # Bar chart por tipo
                    fig_bar = go.Figure(data=[go.Bar(
                        x=tipo_stats['Tipo'],
                        y=tipo_stats['Valor_Total'],
                        text=[f"${val:,.0f}" for val in tipo_stats['Valor_Total']],
                        textposition='auto'
                    )])
                    fig_bar.update_layout(
                        title="Valor por Tipo de Activo",
                        xaxis_title="Tipo",
                        yaxis_title="Valor ($)",
                        height=400
                    )
                    st.plotly_chart(fig_bar, use_container_width=True)
            
            # Histograma de valores individuales
            if len(datos_activos) > 1:
                valores_activos = [a['Valuaci√≥n'] for a in datos_activos if a['Valuaci√≥n'] > 0]
                if valores_activos:
                    fig_hist = go.Figure(data=[go.Histogram(
                        x=valores_activos,
                        nbinsx=min(20, len(valores_activos))
                    )])
                    fig_hist.update_layout(
                        title="Distribuci√≥n de Valores por Activo",
                        xaxis_title="Valor ($)",
                        yaxis_title="Frecuencia",
                        height=400
                    )
                    st.plotly_chart(fig_hist, use_container_width=True)
        
        # Tabla de activos mejorada
        st.markdown("#### üìã Detalle de Activos")
        
        df_display = df_activos.copy()
        df_display['Valuaci√≥n Formateada'] = df_display['Valuaci√≥n'].apply(
            lambda x: f"${x:,.2f}" if x > 0 else "No disponible"
        )
        df_display['Peso (%)'] = (df_display['Valuaci√≥n'] / valor_total * 100).round(2) if valor_total > 0 else 0
        
        # Reordenar columnas
        columns_order = ['S√≠mbolo', 'Descripci√≥n', 'Tipo', 'Cantidad', 'Valuaci√≥n Formateada', 'Peso (%)']
        df_display_final = df_display[columns_order]
        df_display_final = df_display_final.rename(columns={'Valuaci√≥n Formateada': 'Valuaci√≥n'})
        
        # Ordenar por valuaci√≥n descendente
        df_display_final = df_display_final.sort_values('Peso (%)', ascending=False)
        
        st.dataframe(df_display_final, use_container_width=True)
        
        # === ALERTAS Y RECOMENDACIONES ===
        st.markdown("#### üí° An√°lisis y Recomendaciones")
        
        if metricas:
            # An√°lisis de concentraci√≥n
            if metricas['concentracion'] > 0.5:
                st.warning("‚ö†Ô∏è **Portafolio Altamente Concentrado**: Su portafolio tiene un alto nivel de concentraci√≥n. Considere diversificar para reducir el riesgo.")
            elif metricas['concentracion'] > 0.25:
                st.info("‚ÑπÔ∏è **Concentraci√≥n Moderada**: Su portafolio est√° moderadamente concentrado. La diversificaci√≥n adicional podr√≠a reducir el riesgo.")
            else:
                st.success("‚úÖ **Buena Diversificaci√≥n**: Su portafolio muestra un buen nivel de diversificaci√≥n.")
            
            # An√°lisis de riesgo-retorno
            ratio_riesgo_retorno = metricas['retorno_esperado_anual'] / metricas['riesgo_anual'] if metricas['riesgo_anual'] > 0 else 0
            if ratio_riesgo_retorno > 0.5:
                st.success("‚úÖ **Buen Balance Riesgo-Retorno**: La relaci√≥n entre retorno esperado y riesgo es favorable.")
            else:
                st.warning("‚ö†Ô∏è **Revisar Balance Riesgo-Retorno**: El riesgo podr√≠a ser alto en relaci√≥n al retorno esperado.")
        
        if valor_total == 0:
            st.error("‚ùå **Problema de Valuaci√≥n**: No se pudieron obtener valuaciones v√°lidas para los activos.")
            
            if st.button("üîÑ Intentar obtener cotizaciones actuales"):
                with st.spinner("Obteniendo cotizaciones actuales..."):
                    st.info("Funcionalidad de cotizaciones actuales en desarrollo...")
    else:
        st.warning("No se pudieron procesar los datos de los activos")

def mostrar_analisis_portafolio():
    """
    Funci√≥n principal para mostrar el an√°lisis del portafolio del cliente seleccionado
    """
    cliente = st.session_state.cliente_seleccionado
    token_acceso = st.session_state.token_acceso
    fecha_desde = st.session_state.fecha_desde
    fecha_hasta = st.session_state.fecha_hasta
    
    if not cliente:
        st.error("No hay cliente seleccionado")
        return
    
    # Obtener ID del cliente
    id_cliente = cliente.get('numeroCliente', cliente.get('id'))
    nombre_cliente = cliente.get('apellidoYNombre', cliente.get('nombre', 'Cliente'))
    
    st.title(f"üìä An√°lisis de Portafolio - {nombre_cliente}")
    
    # Crear tabs para diferentes an√°lisis
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "üìà Resumen", 
        "üí∞ Estado de Cuenta", 
        "üéØ Optimizaci√≥n", 
        "üìä An√°lisis T√©cnico",
        "üí± Cotizaciones"
    ])
    
    with tab1:
        # Obtener portafolio
        with st.spinner("Cargando portafolio..."):
            portafolio = obtener_portafolio(token_acceso, id_cliente)
        
        if portafolio:
            mostrar_resumen_portafolio(portafolio)
        else:
            st.warning("No se pudo obtener el portafolio del cliente")
    
    with tab2:
        # Mostrar estado de cuenta - intentar primero con ID cliente, luego sin ID
        with st.spinner("Cargando estado de cuenta..."):
            estado_cuenta = obtener_estado_cuenta(token_acceso, id_cliente)
        
        if estado_cuenta:
            mostrar_estado_cuenta(estado_cuenta)
        else:
            st.warning("No se pudo obtener el estado de cuenta")
            
            # Ofrecer alternativa
            st.markdown("#### üîÑ Intentar con endpoint alternativo")
            if st.button("üöÄ Probar endpoint directo"):
                with st.spinner("Probando endpoint directo..."):
                    estado_cuenta_directo = obtener_estado_cuenta(token_acceso, None)
                    if estado_cuenta_directo:
                        mostrar_estado_cuenta(estado_cuenta_directo)
                    else:
                        st.error("‚ùå No se pudo obtener el estado de cuenta con ning√∫n m√©todo")

    with tab3:
        # Optimizaci√≥n de portafolio
        if 'portafolio' not in locals():
            with st.spinner("Cargando portafolio para optimizaci√≥n..."):
                portafolio = obtener_portafolio(token_acceso, id_cliente)
        
        if portafolio:
            mostrar_optimizacion_portafolio(portafolio, token_acceso, fecha_desde, fecha_hasta)
        else:
            st.warning("No se pudo obtener el portafolio para optimizaci√≥n")
    
    with tab4:
        # An√°lisis t√©cnico
        st.markdown("### üìä An√°lisis T√©cnico")
        st.info("üöß Funcionalidad en desarrollo")
        
        # Placeholder para an√°lisis t√©cnico futuro
        if 'portafolio' not in locals():
            portafolio = obtener_portafolio(token_acceso, id_cliente)
        
        if portafolio:
            activos = portafolio.get('activos', [])
            if activos:
                simbolos = [activo.get('titulo', {}).get('simbolo', '') for activo in activos]
                simbolos = [s for s in simbolos if s]
                
                if simbolos:
                    simbolo_seleccionado = st.selectbox(
                        "Seleccione un activo para an√°lisis t√©cnico:",
                        options=simbolos
                    )
                    
                    if simbolo_seleccionado:
                        st.info(f"An√°lisis t√©cnico para {simbolo_seleccionado} estar√° disponible pr√≥ximamente")
    
    with tab5:
        # Cotizaciones y mercado
        mostrar_cotizaciones_mercado(token_acceso)

def mostrar_estado_cuenta(estado_cuenta):
    """
    Muestra el estado de cuenta del cliente con parsing mejorado seg√∫n la estructura de la API
    """
    st.markdown("### üí∞ Estado de Cuenta")
    
    if not estado_cuenta:
        st.warning("No hay datos de estado de cuenta disponibles")
        return
    
    # Mostrar informaci√≥n general
    st.markdown("#### üìã Informaci√≥n General")
    
    # Extraer informaci√≥n seg√∫n la estructura documentada de la API
    total_en_pesos = estado_cuenta.get('totalEnPesos', 0)
    cuentas = estado_cuenta.get('cuentas', [])
    estadisticas = estado_cuenta.get('estadisticas', [])
    
    # Calcular totales agregados
    total_disponible = 0
    total_comprometido = 0
    total_saldo = 0
    total_titulos_valorizados = 0
    total_general = 0
    
    cuentas_por_moneda = {}
    
    for cuenta in cuentas:
        # Extraer valores de cada cuenta
        disponible = float(cuenta.get('disponible', 0))
        comprometido = float(cuenta.get('comprometido', 0))
        saldo = float(cuenta.get('saldo', 0))
        titulos_valorizados = float(cuenta.get('titulosValorizados', 0))
        total_cuenta = float(cuenta.get('total', 0))
        moneda = cuenta.get('moneda', 'peso_Argentino')
        tipo = cuenta.get('tipo', 'N/A')
        
        # Sumar totales
        total_disponible += disponible
        total_comprometido += comprometido
        total_saldo += saldo
        total_titulos_valorizados += titulos_valorizados
        total_general += total_cuenta
        
        # Agrupar por moneda
        if moneda not in cuentas_por_moneda:
            cuentas_por_moneda[moneda] = {
                'disponible': 0,
                'saldo': 0,
                'total': 0,
                'cuentas': []
            }
        
        cuentas_por_moneda[moneda]['disponible'] += disponible
        cuentas_por_moneda[moneda]['saldo'] += saldo
        cuentas_por_moneda[moneda]['total'] += total_cuenta
        cuentas_por_moneda[moneda]['cuentas'].append(cuenta)
    
    # Mostrar m√©tricas principales
    col1, col2, col3, col4 = st.columns(4)
    
    col1.metric(
        "Total General", 
        f"${total_general:,.2f}",
        help="Suma total de todas las cuentas"
    )
    
    col2.metric(
        "Total en Pesos", 
        f"AR$ {total_en_pesos:,.2f}",
        help="Total expresado en pesos argentinos seg√∫n la API"
    )
    
    col3.metric(
        "Disponible Total", 
        f"${total_disponible:,.2f}",
        help="Total disponible para operar"
    )
    
    col4.metric(
        "T√≠tulos Valorizados", 
        f"${total_titulos_valorizados:,.2f}",
        help="Valor total de t√≠tulos en cartera"
    )
    
    # Mostrar informaci√≥n por moneda
    if cuentas_por_moneda:
        st.markdown("#### üí± Distribuci√≥n por Moneda")
        
        for moneda, datos in cuentas_por_moneda.items():
            # Convertir nombre de moneda a formato legible
            nombre_moneda = {
                'peso_Argentino': 'Pesos Argentinos',
                'dolar_Estadounidense': 'D√≥lares Estadounidenses',
                'euro': 'Euros'
            }.get(moneda, moneda)
            
            with st.expander(f"üí∞ {nombre_moneda} ({len(datos['cuentas'])} cuenta(s))"):
                col1, col2, col3 = st.columns(3)
                
                col1.metric("Disponible", f"${datos['disponible']:,.2f}")
                col2.metric("Saldo", f"${datos['saldo']:,.2f}")
                col3.metric("Total", f"${datos['total']:,.2f}")
    
    # Mostrar detalles de cuentas
    if cuentas:
        st.markdown("#### üìä Detalle de Cuentas")
        
        # Crear DataFrame con informaci√≥n de cuentas
        datos_cuentas = []
        for cuenta in cuentas:
            datos_cuentas.append({
                'N√∫mero': cuenta.get('numero', 'N/A'),
                'Tipo': cuenta.get('tipo', 'N/A').replace('_', ' ').title(),
                'Moneda': cuenta.get('moneda', 'N/A').replace('_', ' ').title(),
                'Disponible': f"${cuenta.get('disponible', 0):,.2f}",
                'Comprometido': f"${cuenta.get('comprometido', 0):,.2f}",
                'Saldo': f"${cuenta.get('saldo', 0):,.2f}",
                'T√≠tulos Valorizados': f"${cuenta.get('titulosValorizados', 0):,.2f}",
                'Total': f"${cuenta.get('total', 0):,.2f}",
                'Estado': cuenta.get('estado', 'N/A').title()
            })
        
        if datos_cuentas:
            df_cuentas = pd.DataFrame(datos_cuentas)
            st.dataframe(df_cuentas, use_container_width=True)
    
    # Mostrar estad√≠sticas si est√°n disponibles
    if estadisticas:
        st.markdown("#### üìà Estad√≠sticas")
        
        datos_estadisticas = []
        for stat in estadisticas:
            datos_estadisticas.append({
                'Descripci√≥n': stat.get('descripcion', 'N/A'),
                'Cantidad': stat.get('cantidad', 0),
                'Volumen': f"${stat.get('volumen', 0):,.2f}"
            })
        
        if datos_estadisticas:
            df_estadisticas = pd.DataFrame(datos_estadisticas)
            st.dataframe(df_estadisticas, use_container_width=True)
    
    # Informaci√≥n de debug
    with st.expander("üîç Informaci√≥n de Debug - Estructura del Estado de Cuenta"):
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**Estructura encontrada:**")
            if isinstance(estado_cuenta, dict):
                campos_raiz = list(estado_cuenta.keys())
                st.code('\n'.join(sorted(campos_raiz)))
                
                st.markdown("**Resumen de valores:**")
                resumen = []
                resumen.append(f"Total en Pesos: AR$ {total_en_pesos:,.2f}")
                resumen.append(f"N√∫mero de cuentas: {len(cuentas)}")
                resumen.append(f"Total general calculado: ${total_general:,.2f}")
                resumen.append(f"Estad√≠sticas disponibles: {len(estadisticas)}")
                st.code('\n'.join(resumen))
            else:
                st.text(f"Tipo de datos: {type(estado_cuenta)}")
        
        with col2:
            st.markdown("**Estructura completa:**")
            st.json(estado_cuenta)
    
    # Alertas y recomendaciones
    if total_general == 0 and total_en_pesos == 0:
        st.warning("‚ö†Ô∏è No se encontraron saldos en las cuentas")
        st.markdown("#### üí° Posibles causas:")
        st.markdown("""
        1. **Cuentas vac√≠as**: Las cuentas pueden no tener saldos actualmente
        2. **Permisos**: Verificar que tenga permisos para ver estados de cuenta
        3. **Sincronizaci√≥n**: Los datos pueden estar siendo actualizados por IOL
        """)
    
    elif total_disponible == 0 and total_titulos_valorizados > 0:
        st.info("‚ÑπÔ∏è **Cartera invertida**: Todo el capital est√° invertido en t√≠tulos")
    
    elif total_disponible > 0:
        porcentaje_invertido = (total_titulos_valorizados / total_general * 100) if total_general > 0 else 0
        if porcentaje_invertido < 50:
            st.info(f"üí° **Oportunidad de inversi√≥n**: Tiene {porcentaje_invertido:.1f}% invertido. Considere revisar oportunidades de inversi√≥n.")
        else:
            st.success(f"‚úÖ **Buena distribuci√≥n**: Tiene {porcentaje_invertido:.1f}% de su capital invertido.")

def mostrar_cotizaciones_mercado(token_acceso):
    """
    Muestra cotizaciones y datos de mercado
    """
    st.markdown("### üí± Cotizaciones y Mercado")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### üí∞ Cotizaci√≥n MEP")
        
        # Formulario para consultar MEP
        with st.form("mep_form"):
            simbolo_mep = st.text_input("S√≠mbolo para MEP", value="AL30", help="Ej: AL30, GD30, etc.")
            id_plazo_compra = st.number_input("ID Plazo Compra", value=1, min_value=1)
            id_plazo_venta = st.number_input("ID Plazo Venta", value=1, min_value=1)
            
            if st.form_submit_button("Consultar MEP"):
                if simbolo_mep:
                    with st.spinner("Consultando cotizaci√≥n MEP..."):
                        cotizacion_mep = obtener_cotizacion_mep(
                            token_acceso, simbolo_mep, id_plazo_compra, id_plazo_venta
                        )
                    
                    if cotizacion_mep:
                        st.success("‚úÖ Cotizaci√≥n MEP obtenida")
                        
                        # Mostrar datos de MEP
                        if isinstance(cotizacion_mep, dict):
                            # Extraer precio si est√° disponible
                            precio_mep = cotizacion_mep.get('precio', cotizacion_mep.get('cotizacion', 'N/A'))
                            
                            col_mep1, col_mep2 = st.columns(2)
                            col_mep1.metric("S√≠mbolo", simbolo_mep)
                            col_mep2.metric("Precio MEP", f"${precio_mep}" if precio_mep != 'N/A' else 'N/A')
                        
                        with st.expander("Ver detalles MEP"):
                            st.json(cotizacion_mep)
                    else:
                        st.error("‚ùå No se pudo obtener la cotizaci√≥n MEP")
    
    with col2:
        st.markdown("#### üè¶ Tasas de Cauci√≥n")
        
        if st.button("üîÑ Actualizar Tasas de Cauci√≥n"):
            with st.spinner("Consultando tasas de cauci√≥n..."):
                tasas_caucion = obtener_tasas_caucion(token_acceso)
            
            if tasas_caucion:
                st.success("‚úÖ Tasas de cauci√≥n obtenidas")
                
                # Mostrar tasas si es una lista
                if isinstance(tasas_caucion, list) and tasas_caucion:
                    df_tasas = pd.DataFrame(tasas_caucion)
                    
                    # Mostrar solo columnas relevantes si est√°n disponibles
                    columnas_relevantes = ['simbolo', 'tasa', 'bid', 'offer', 'ultimo']
                    columnas_disponibles = [col for col in columnas_relevantes if col in df_tasas.columns]
                    
                    if columnas_disponibles:
                        st.dataframe(df_tasas[columnas_disponibles].head(10))
                    else:
                        st.dataframe(df_tasas.head(10))
                
                with st.expander("Ver datos completos de cauci√≥n"):
                    st.json(tasas_caucion)
            else:
                st.error("‚ùå No se pudieron obtener las tasas de cauci√≥n")

# --- CLASES Y FUNCIONES COMPLETAS DE MACHINE LEARNING PARA FINANZAS CUANTITATIVAS ---

def load_timeseries(ric, directory=None, data_source='iol', token_portador=None, fecha_desde=None, fecha_hasta=None):
    """
    Carga series de tiempo desde diferentes fuentes: archivos CSV, API de IOL, o Yahoo Finance
    """
    if data_source == 'csv' and directory:
        # Cargar desde archivo CSV
        import os
        path = os.path.join(directory, f"{ric}.csv")
        print(f"Cargando datos desde {path}")
        try:
            raw_data = pd.read_csv(path)
        except Exception as e:
            print(f"Error al cargar el archivo {path}: {e}")
            return pd.DataFrame()
        
        t = pd.DataFrame()
        
        if 'datetime' in raw_data.columns:
            # Formato del archivo ^FCHI.csv
            t['date'] = pd.to_datetime(raw_data['datetime'], utc=True, errors='coerce').dt.normalize()
            t['close'] = raw_data['Close']
        elif 'fechaHora' in raw_data.columns:
            # Formato del archivo ALUA.csv
            t['date'] = pd.to_datetime(raw_data['fechaHora'], utc=True, errors='coerce').dt.normalize()
            t['close'] = raw_data['ultimoPrecio']
        elif 'Date' in raw_data.columns and 'Close' in raw_data.columns:
            # Formato del archivo con columnas 'Date' y 'Close'
            t['date'] = pd.to_datetime(raw_data['Date'], utc=True, errors='coerce').dt.normalize()
            t['close'] = raw_data['Close']
        else:
            print(f"Formato de archivo desconocido para {ric}. Columnas disponibles: {raw_data.columns}")
            return pd.DataFrame()
            
    elif data_source == 'iol' and token_portador and fecha_desde and fecha_hasta:
        # Cargar desde API de IOL
        fecha_desde_str = fecha_desde.strftime('%Y-%m-%d') if hasattr(fecha_desde, 'strftime') else str(fecha_desde)
        fecha_hasta_str = fecha_hasta.strftime('%Y-%m-%d') if hasattr(fecha_hasta, 'strftime') else str(fecha_hasta)
        
        # Determinar mercados seg√∫n el tipo de instrumento
        if ric.upper() == "ADCGLOA":
            mercados = ['FCI']
        elif ric.upper().startswith("AE") or ric.upper().endswith("D") or ric.upper().endswith("C") or ric.upper().endswith("O"):
            mercados = ['bCBA']
        elif ric.upper().endswith("48") or ric.upper().endswith("30") or ric.upper().endswith("29"):
            mercados = ['bCBA']
        elif ric.upper().startswith("MERV") or ric.upper().startswith("OPC"):
            mercados = ['Opciones']
        else:
            mercados = ['bCBA', 'nYSE', 'nASDAQ', 'rOFEX']
        
        # Intentar obtener datos de cada mercado
        for mercado in mercados:
            try:
                simbolo_consulta = ric
                if mercado == 'bCBA' and (ric.upper().endswith("D") or ric.upper().endswith("C") or ric.upper().endswith("O") or ric.upper().startswith("AE")):
                    clase_d = obtener_clase_d(ric, mercado, token_portador)
                    if clase_d:
                        simbolo_consulta = clase_d

                serie = obtener_serie_historica_iol(
                    token_portador, mercado, simbolo_consulta,
                    fecha_desde_str, fecha_hasta_str
                )

                if serie is not None and len(serie) > 10:
                    serie_clean = serie.dropna()
                    if len(serie_clean) > 10 and serie_clean.nunique() > 1 and serie_clean.std() > 0:
                        t = pd.DataFrame()
                        t['date'] = serie_clean.index
                        t['close'] = serie_clean.values
                        break
            except Exception:
                continue
        
        if 't' not in locals() or t.empty:
            # Fallback a yfinance
            try:
                serie_yf = obtener_datos_alternativos_yfinance(ric, fecha_desde, fecha_hasta)
                if serie_yf is not None and len(serie_yf) > 10:
                    t = pd.DataFrame()
                    t['date'] = serie_yf.index
                    t['close'] = serie_yf.values
            except Exception:
                return pd.DataFrame()
    
    elif data_source == 'yfinance':
        # Cargar desde Yahoo Finance
        try:
            import yfinance as yf
            ticker = yf.Ticker(ric)
            data = ticker.history(start=fecha_desde, end=fecha_hasta)
            if not data.empty:
                t = pd.DataFrame()
                t['date'] = data.index
                t['close'] = data['Close'].values
        except Exception as e:
            print(f"Error cargando datos de Yahoo Finance para {ric}: {e}")
            return pd.DataFrame()
            'Sharpe Ratio': sharpe,
            'VaR 95%': var_95
        }
    
    def plot_histogram_streamlit(self, title="Distribuci√≥n de Retornos"):
        """
        Crea un histograma de retornos usando Plotly para Streamlit
        """
        if self.portfolio_returns is None or len(self.portfolio_returns) == 0:
            # Crear gr√°fico vac√≠o
            fig = go.Figure()
            fig.add_annotation(
                text="No hay datos suficientes para mostrar",
                xref="paper", yref="paper",
                x=0.5, y=0.5, showarrow=False
            )
            fig.update_layout(title=title)
            return fig
        
        fig = go.Figure(data=[go.Histogram(
            x=self.portfolio_returns,
            nbinsx=30,
            name="Retornos del Portafolio"
        )])
        
        # Agregar l√≠neas de m√©tricas importantes
        fig.add_vline(x=self.mean_daily, line_dash="dash", line_color="red", 
                     annotation_text=f"Media: {self.mean_daily:.4f}")
        fig.add_vline(x=self.var_95, line_dash="dash", line_color="orange", 
                     annotation_text=f"VaR 95%: {self.var_95:.4f}")
        
        fig.update_layout(
            title=f"{title}",
            xaxis_title="Retorno",
            yaxis_title="Frecuencia",
            showlegend=False
        )
        
        return fig

# Enhanced Portfolio Management Classes
class manager:
    def __init__(self, rics, notional, token_portador=None, fecha_desde=None, fecha_hasta=None):
        self.rics = rics
        self.notional = notional
        self.token_portador = token_portador
        self.fecha_desde = fecha_desde
        self.fecha_hasta = fecha_hasta
        self.timeseries = None
        self.returns = None
        self.cov_matrix = None
        self.mean_returns = None
        self.risk_free_rate = 0.40  # Tasa libre de riesgo anual
        self.data_loaded = False

    def load_intraday_timeseries(self, ticker):
        """
        Carga series hist√≥ricas usando las mismas funciones que para estad√≠sticas del portafolio
        """
        if self.token_portador and self.fecha_desde and self.fecha_hasta:
            # Usar la funci√≥n principal de obtenci√≥n de datos hist√≥ricos
            fecha_desde_str = self.fecha_desde.strftime('%Y-%m-%d') if hasattr(self.fecha_desde, 'strftime') else str(self.fecha_desde)
            fecha_hasta_str = self.fecha_hasta.strftime('%Y-%m-%d') if hasattr(self.fecha_hasta, 'strftime') else str(self.fecha_hasta)
            
            # Determinar tipo de instrumento usando la misma l√≥gica
            if ticker.upper() == "ADCGLOA":
                mercados = ['FCI']
            elif ticker.upper().startswith("AE") or ticker.upper().endswith("D") or ticker.upper().endswith("C") or ticker.upper().endswith("O"):
                # Bonos (puedes ajustar la l√≥gica seg√∫n nomenclatura)
                mercados = ['bCBA']
            else:
                mercados = ['bCBA', 'nYSE', 'nASDAQ', 'rOFEX', 'Opciones', 'FCI']
            
            # Intentar obtener datos de cada mercado
            for mercado in mercados:
                try:
                    simbolo_consulta = ticker
                    if mercado not in ['Opciones', 'FCI']:
                        clase_d = obtener_clase_d(ticker, mercado, self.token_portador)
                        if clase_d:
                            simbolo_consulta = clase_d

                    serie = obtener_serie_historica_iol(
                        self.token_portador, mercado, simbolo_consulta,
                        fecha_desde_str, fecha_hasta_str
                    )

                    if serie is not None and len(serie) > 10:
                        # Verificar que la serie tenga valores v√°lidos y variaci√≥n
                        serie_clean = serie.dropna()
                        if len(serie_clean) > 10 and serie_clean.nunique() > 1 and serie_clean.std() > 0:
                            return serie
                except Exception:
                    continue
            
            # Fallback a yfinance si IOL no funciona
            try:
                serie_yf = obtener_datos_alternativos_yfinance(
                    ticker, self.fecha_desde, self.fecha_hasta
                )
                if serie_yf is not None and len(serie_yf) > 10:
                    serie_yf_clean = serie_yf.dropna()
                    if len(serie_yf_clean) > 10 and serie_yf_clean.nunique() > 1 and serie_yf_clean.std() > 0:
                        return serie_yf
            except Exception:
                pass        
        return None

    def synchronise_timeseries(self):
        """
        Sincroniza las series temporales usando SIEMPRE get_historical_data_for_optimization,
        igual que las estad√≠sticas del portafolio.
        """
        if self.token_portador and self.fecha_desde and self.fecha_hasta:
            mean_returns, cov_matrix, df_precios = get_historical_data_for_optimization(
                self.token_portador, self.rics, self.fecha_desde, self.fecha_hasta
            )
            if mean_returns is not None and cov_matrix is not None and df_precios is not None:
                self.timeseries = df_precios
                self.returns = df_precios.pct_change().dropna()
                self.cov_matrix = cov_matrix
                self.mean_returns = mean_returns
                self.data_loaded = True
                return True
            else:
                st.error("‚ùå No se pudieron sincronizar las series temporales")
                return False

        # Fallback al m√©todo original si no hay token
        dic_timeseries = {}
        for ric in self.rics:
            serie = self.load_intraday_timeseries(ric)
            if serie is not None:
                dic_timeseries[ric] = serie

        if dic_timeseries:
            self.timeseries = pd.DataFrame(dic_timeseries)
            return True
        return False

    def compute_covariance(self):
        """
        Computa la matriz de covarianza usando datos sincronizados
        """
        if not self.data_loaded:
            success = self.synchronise_timeseries()
            if not success:
                return None, None
        
        if self.cov_matrix is not None and self.mean_returns is not None:
            return self.cov_matrix, self.mean_returns
        
        # M√©todo de respaldo si no se cargaron datos con la funci√≥n principal
        if self.timeseries is not None and len(self.timeseries) > 0:
            # Calcular retornos logar√≠tmicos
            returns_matrix = {}
            for ric in self.rics:
                if ric in self.timeseries.columns:
                    prices = self.timeseries[ric].dropna()
                    if len(prices) > 1:
                        returns = np.log(prices / prices.shift(1)).dropna()
                        if len(returns) > 10 and returns.std() > 0:
                            returns_matrix[ric] = returns
            
            if len(returns_matrix) >= 2:
                # Convertir a DataFrame para alinear fechas
                self.returns = pd.DataFrame(returns_matrix)
                
                # Calcular matriz de covarianza y retornos medios
                self.cov_matrix = self.returns.cov() * 252  # Anualizar
                self.mean_returns = self.returns.mean() * 252  # Anualizar
                
                return self.cov_matrix, self.mean_returns
        
        return None, None

    def compute_portfolio(self, portfolio_type=None, target_return=None):
        cov_matrix, mean_returns = self.compute_covariance()
        
        if cov_matrix is None or mean_returns is None:
            st.error("‚ùå No se pudo calcular la matriz de covarianza")
            return None
            
        n_assets = len(mean_returns)
        if n_assets < 2:
            st.error("‚ùå Se necesitan al menos 2 activos para optimizaci√≥n")
            return None
            
        bounds = tuple((0, 1) for _ in range(n_assets))
        
        if portfolio_type == 'equi-weight':
            # Pesos iguales
            weights = np.ones(n_assets) / n_assets
            return self._create_output(weights, mean_returns.index)
        
        # Configurar restricciones seg√∫n el tipo de portafolio
        constraints = [{'type': 'eq', 'fun': lambda x: np.sum(x) - 1}]
        
        if portfolio_type == 'min-variance-l1':
            # Minimizar varianza con restricci√≥n L1
            constraints.append({'type': 'ineq', 'fun': lambda x: 1 - np.sum(np.abs(x))})
        elif portfolio_type == 'min-variance-l2':
            # Minimizar varianza con restricci√≥n L2
            constraints.append({'type': 'ineq', 'fun': lambda x: 1 - np.sum(x**2)})
        elif portfolio_type == 'markowitz' and target_return is not None:
            # Optimizaci√≥n con retorno objetivo
            constraints.append({
                'type': 'eq', 
                'fun': lambda x: np.sum(mean_returns.values * x) - target_return
            })
        
        try:
            if portfolio_type == 'markowitz' and target_return is None:
                # Maximizar Sharpe Ratio
                def neg_sharpe_ratio(weights):
                    port_ret = np.sum(mean_returns.values * weights)
                    port_vol = np.sqrt(portfolio_variance(weights, cov_matrix.values))
                    if port_vol == 0:
                        return np.inf
                    return -(port_ret - self.risk_free_rate) / port_vol
                
                objective = neg_sharpe_ratio
            else:
                # Minimizar varianza
                objective = lambda x: portfolio_variance(x, cov_matrix.values)
            
            # Optimizaci√≥n
            initial_guess = np.ones(n_assets) / n_assets
            
            result = op.minimize(
                objective, 
                x0=initial_guess,
                method='SLSQP',
                bounds=bounds,
                constraints=constraints,
                options={'maxiter': 1000, 'ftol': 1e-9}
            )
            
            if result.success:
                return self._create_output(result.x, mean_returns.index)
            else:
                st.warning(f"‚ö†Ô∏è Optimizaci√≥n no convergi√≥: {result.message}. Usando pesos iguales.")
                weights = np.ones(n_assets) / n_assets
                return self._create_output(weights, mean_returns.index)
                
        except Exception as e:
            st.error(f"‚ùå Error en optimizaci√≥n: {str(e)}. Usando pesos iguales.")
            weights = np.ones(n_assets) / n_assets
            return self._create_output(weights, mean_returns.index)

    def _create_output(self, weights, asset_names):
        """Crea un objeto output con los pesos optimizados"""
        if self.returns is None or len(self.returns) == 0:
            st.error("‚ùå No hay datos de retornos disponibles")
            return None
            
        try:
            # Asegurar que los nombres de activos coincidan
            common_assets = [asset for asset in asset_names if asset in self.returns.columns]
            if len(common_assets) != len(weights):
                st.warning(f"‚ö†Ô∏è Ajustando pesos para {len(common_assets)} activos comunes")
                # Reajustar pesos para activos comunes
                weights = weights[:len(common_assets)]
                weights = weights / weights.sum()  # Renormalizar
                asset_names = common_assets
            
            # Calcular retornos del portafolio
            portfolio_returns = self.returns[common_assets].dot(weights)
            
            if len(portfolio_returns) == 0:
                st.error("‚ùå No se pudieron calcular retornos del portafolio")
                return None
            
            # Crear objeto output
            port_output = output(portfolio_returns.values, self.notional)
            port_output.weights = weights
            port_output.asset_names = list(asset_names)
            
            # Calcular m√©tricas del portafolio
            port_ret = np.sum(self.mean_returns[common_assets].values * weights)
            port_vol = np.sqrt(portfolio_variance(weights, self.cov_matrix.loc[common_assets, common_assets].values))
            
            # Actualizar m√©tricas anualizadas
            port_output.return_annual = port_ret
            port_output.volatility_annual = port_vol
            
            # Crear DataFrame de asignaci√≥n
            volatilities = []
            returns_list = []
            for asset in common_assets:
                if asset in self.returns.columns:
                    vol = self.returns[asset].std() * np.sqrt(252)
                    ret = self.mean_returns[asset] if asset in self.mean_returns.index else 0
                else:
                    vol = 0
                    ret = 0
                volatilities.append(vol)
                returns_list.append(ret)
            
            port_output.dataframe_allocation = pd.DataFrame({
                'rics': common_assets,
                'weights': weights,
                'volatilities': volatilities,
                'returns': returns_list
            })
            
            return port_output
            
        except Exception as e:
            st.error(f"‚ùå Error creando output del portafolio: {str(e)}")
            return None

def calcular_metricas_avanzadas_ml(datos_retornos, ventana_volatilidad=30):
    """
    Calcula m√©tricas avanzadas usando Machine Learning para an√°lisis de riesgo
    """
    try:
        if len(datos_retornos) < ventana_volatilidad:
            return None
        
        # Convertir a DataFrame si es necesario
        if isinstance(datos_retornos, pd.Series):
            datos_retornos = datos_retornos.to_frame('retornos')
        
        # Calcular caracter√≠sticas t√©cnicas
        caracteristicas = {}
        
        for columna in datos_retornos.columns:
            serie = datos_retornos[columna].dropna()
            
            if len(serie) < 10:
                continue
                
            # M√©tricas b√°sicas
            caracteristicas[f'{columna}_media'] = serie.mean()
            caracteristicas[f'{columna}_volatilidad'] = serie.std()
            caracteristicas[f'{columna}_asimetria'] = serie.skew()
            caracteristicas[f'{columna}_curtosis'] = serie.kurtosis()
            
            # Volatilidad rodante
            vol_rodante = serie.rolling(window=min(ventana_volatilidad, len(serie))).std()
            caracteristicas[f'{columna}_vol_max'] = vol_rodante.max()
            caracteristicas[f'{columna}_vol_min'] = vol_rodante.min()
            caracteristicas[f'{columna}_vol_tendencia'] = np.polyfit(range(len(vol_rodante.dropna())), vol_rodante.dropna(), 1)[0]
            
            # M√©tricas de riesgo
            var_5 = np.percentile(serie, 5)
            var_1 = np.percentile(serie, 1)
            cvar_5 = serie[serie <= var_5].mean()
            
            caracteristicas[f'{columna}_var_5'] = var_5
            caracteristicas[f'{columna}_var_1'] = var_1
            caracteristicas[f'{columna}_cvar_5'] = cvar_5
            
            # M√©tricas de momentum
            if len(serie) > 5:
                momentum_5 = serie.rolling(5).mean().iloc[-1] - serie.rolling(5).mean().iloc[-5] if len(serie) >= 10 else 0
                caracteristicas[f'{columna}_momentum_5'] = momentum_5
            
            # Drawdown m√°ximo
            acumulado = (1 + serie).cumprod()
            peak = acumulado.expanding().max()
            drawdown = (acumulado - peak) / peak
            caracteristicas[f'{columna}_max_drawdown'] = drawdown.min()
        
        return caracteristicas
        
    except Exception as e:
        st.error(f"Error calculando m√©tricas ML: {str(e)}")
        return None

def modelo_regresion_lineal_portafolio(datos_precios, variable_objetivo='retorno_portafolio', test_size=0.3):
    """
    Implementa modelo de regresi√≥n lineal para predicci√≥n de retornos del portafolio
    """
    try:
        st.markdown("#### üìà Modelo de Regresi√≥n Lineal")
        
        if datos_precios is None or len(datos_precios) < 50:
            st.warning("‚ö†Ô∏è Datos insuficientes para entrenamiento del modelo (m√≠nimo 50 observaciones)")
            return None
        
        # Calcular retornos
        retornos = datos_precios.pct_change().dropna()
        
        if len(retornos.columns) < 2:
            st.warning("‚ö†Ô∏è Se necesitan al menos 2 activos para el modelo")
            return None
        
        # Preparar datos
        # Variable objetivo: retorno promedio del portafolio
        y = retornos.mean(axis=1).values
        
        # Variables explicativas: retornos individuales y caracter√≠sticas t√©cnicas
        X = retornos.values
        
        # Dividir datos
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)
        
        # Normalizar datos
        scaler_X = StandardScaler()
        X_train_scaled = scaler_X.fit_transform(X_train)
        X_test_scaled = scaler_X.transform(X_test)
        
        # Entrenar modelos
        modelos = {
            'Regresi√≥n Lineal Simple': LinearRegression(),
            'Ridge (L2)': Ridge(alpha=1.0),
            'Lasso (L1)': Lasso(alpha=0.01),
            'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42)
        }
        
        resultados = {}
        
        for nombre, modelo in modelos.items():
            # Entrenar
            modelo.fit(X_train_scaled, y_train)
            
            # Predecir
            y_pred_train = modelo.predict(X_train_scaled)
            y_pred_test = modelo.predict(X_test_scaled)
            
            # M√©tricas
            mse_train = mean_squared_error(y_train, y_pred_train)
            mse_test = mean_squared_error(y_test, y_pred_test)
            r2_train = r2_score(y_train, y_pred_train)
            r2_test = r2_score(y_test, y_pred_test)
            
            resultados[nombre] = {
                'modelo': modelo,
                'mse_train': mse_train,
                'mse_test': mse_test,
                'r2_train': r2_train,
                'r2_test': r2_test,
                'y_pred_test': y_pred_test,
                'y_test': y_test
            }
        
        # Mostrar resultados
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**üìä M√©tricas de Rendimiento**")
            df_metricas = pd.DataFrame({
                modelo: {
                    'R¬≤ Entrenamiento': f"{res['r2_train']:.4f}",
                    'R¬≤ Prueba': f"{res['r2_test']:.4f}",
                    'MSE Entrenamiento': f"{res['mse_train']:.6f}",
                    'MSE Prueba': f"{res['mse_test']:.6f}",
                    'Sobreajuste': 'S√≠' if res['r2_train'] - res['r2_test'] > 0.1 else 'No'
                }
                for modelo, res in resultados.items()
            }).T
            
            st.dataframe(df_metricas)
        
        with col2:
            # Gr√°fico de predicciones vs real
            mejor_modelo = max(resultados.keys(), key=lambda x: resultados[x]['r2_test'])
            
            fig = go.Figure()
            fig.add_trace(go.Scatter(
                x=resultados[mejor_modelo]['y_test'],
                y=resultados[mejor_modelo]['y_pred_test'],
                mode='markers',
                name='Predicciones',
                text=[f"Real: {real:.4f}<br>Pred: {pred:.4f}" 
                      for real, pred in zip(resultados[mejor_modelo]['y_test'], 
                                          resultados[mejor_modelo]['y_pred_test'])]
            ))
            
            # L√≠nea diagonal perfecta
            min_val = min(min(resultados[mejor_modelo]['y_test']), 
                         min(resultados[mejor_modelo]['y_pred_test']))
            max_val = max(max(resultados[mejor_modelo]['y_test']), 
                         max(resultados[mejor_modelo]['y_pred_test']))
            
            fig.add_trace(go.Scatter(
                x=[min_val, max_val],
                y=[min_val, max_val],
                mode='lines',
                name='Predicci√≥n Perfecta',
                line=dict(dash='dash', color='red')
            ))
            
            fig.update_layout(
                title=f"Predicciones vs Real - {mejor_modelo}",
                xaxis_title="Valor Real",
                yaxis_title="Valor Predicho",
                height=400
            )
            
            st.plotly_chart(fig, use_container_width=True)
        
        # Interpretaci√≥n del modelo
        st.markdown("#### üéØ Interpretaci√≥n del Modelo")
        
        mejor_res = resultados[mejor_modelo]
        r2_test = mejor_res['r2_test']
        
        if r2_test > 0.7:
            st.success(f"‚úÖ **Excelente ajuste**: El modelo {mejor_modelo} explica el {r2_test:.1%} de la variabilidad")
        elif r2_test > 0.5:
            st.info(f"‚ÑπÔ∏è **Buen ajuste**: El modelo {mejor_modelo} explica el {r2_test:.1%} de la variabilidad")
        elif r2_test > 0.3:
            st.warning(f"‚ö†Ô∏è **Ajuste moderado**: El modelo {mejor_modelo} explica el {r2_test:.1%} de la variabilidad")
        else:
            st.error(f"‚ùå **Ajuste deficiente**: El modelo solo explica el {r2_test:.1%} de la variabilidad")
        
        # Mostrar importancia de caracter√≠sticas para Random Forest
        if mejor_modelo == 'Random Forest':
            modelo_rf = resultados[mejor_modelo]['modelo']
            importancias = modelo_rf.feature_importances_
            
            fig_imp = go.Figure(data=[go.Bar(
                x=retornos.columns,
                y=importancias,
                text=[f"{imp:.3f}" for imp in importancias],
                textposition='auto'
            )])
            
            fig_imp.update_layout(
                title="Importancia de Caracter√≠sticas - Random Forest",
                xaxis_title="Activos",
                yaxis_title="Importancia",
                height=400
            )
            
            st.plotly_chart(fig_imp, use_container_width=True)
        
        return resultados
        
    except Exception as e:
        st.error(f"Error en modelo de regresi√≥n lineal: {str(e)}")
        return None

def modelo_clasificacion_se√±ales_trading(datos_precios, horizonte_prediccion=5, test_size=0.3):
    """
    Implementa modelos de clasificaci√≥n para generar se√±ales de trading
    """
    try:
        st.markdown("#### üéØ Modelo de Clasificaci√≥n - Se√±ales de Trading")
        
        if datos_precios is None or len(datos_precios) < 100:
            st.warning("‚ö†Ô∏è Datos insuficientes para modelo de clasificaci√≥n (m√≠nimo 100 observaciones)")
            return None
        
        # Calcular retornos
        retornos = datos_precios.pct_change().dropna()
        
        # Crear caracter√≠sticas t√©cnicas
        caracteristicas = pd.DataFrame(index=retornos.index)
        
        for col in retornos.columns:
            serie = retornos[col]
            
            # Medias m√≥viles de retornos
            caracteristicas[f'{col}_ma_5'] = serie.rolling(5).mean()
            caracteristicas[f'{col}_ma_10'] = serie.rolling(10).mean()
            caracteristicas[f'{col}_ma_20'] = serie.rolling(20).mean()
            
            # Volatilidad rodante
            caracteristicas[f'{col}_vol_5'] = serie.rolling(5).std()
            caracteristicas[f'{col}_vol_10'] = serie.rolling(10).std()
            
            # Momentum
            caracteristicas[f'{col}_momentum_3'] = serie.rolling(3).sum()
            caracteristicas[f'{col}_momentum_5'] = serie.rolling(5).sum()
            
            # RSI simplificado
            delta = serie.diff()
            gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
            loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
            rs = gain / loss
            caracteristicas[f'{col}_rsi'] = 100 - (100 / (1 + rs))
        
        # Variable objetivo: clasificaci√≥n de retornos futuros del portafolio
        retorno_portafolio = retornos.mean(axis=1)
        retorno_futuro = retorno_portafolio.shift(-horizonte_prediccion)
        
        # Clasificar en tres categor√≠as basadas en cuantiles
        quantiles = retorno_futuro.quantile([0.33, 0.67])
        
        def clasificar_retorno(ret):
            if pd.isna(ret):
                return np.nan
            elif ret <= quantiles.iloc[0]:
                return 0  # Bajo (Vender)
            elif ret <= quantiles.iloc[1]:
                return 1  # Medio (Mantener)
            else:
                return 2  # Alto (Comprar)
        
        y = retorno_futuro.apply(clasificar_retorno)
        
        # Preparar datos
        datos_completos = pd.concat([caracteristicas, y.rename('target')], axis=1).dropna()
        
        if len(datos_completos) < 50:
            st.warning("‚ö†Ô∏è Datos insuficientes despu√©s de crear caracter√≠sticas")
            return None
        
        X = datos_completos.drop('target', axis=1).values
        y = datos_completos['target'].values
        
        # Dividir datos
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, 
                                                            random_state=42, stratify=y)
        
        # Normalizar caracter√≠sticas
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        # Entrenar modelos
        modelos = {
            'Regresi√≥n Log√≠stica': LogisticRegression(random_state=42, max_iter=1000),
            'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),
            'SVM': SVC(kernel='rbf', random_state=42, probability=True),
            'Red Neuronal': MLPClassifier(hidden_layer_sizes=(50, 25), random_state=42, max_iter=500)
        }
        
        resultados_clf = {}
        
        for nombre, modelo in modelos.items():
            try:
                # Entrenar
                modelo.fit(X_train_scaled, y_train)
                
                # Predecir
                y_pred_train = modelo.predict(X_train_scaled)
                y_pred_test = modelo.predict(X_test_scaled)
                y_proba_test = modelo.predict_proba(X_test_scaled)
                
                # M√©tricas
                acc_train = accuracy_score(y_train, y_pred_train)
                acc_test = accuracy_score(y_test, y_pred_test)
                precision = precision_score(y_test, y_pred_test, average='weighted', zero_division=0)
                recall = recall_score(y_test, y_pred_test, average='weighted', zero_division=0)
                f1 = f1_score(y_test, y_pred_test, average='weighted', zero_division=0)
                
                resultados_clf[nombre] = {
                    'modelo': modelo,
                    'acc_train': acc_train,
                    'acc_test': acc_test,
                    'precision': precision,
                    'recall': recall,
                    'f1': f1,
                    'y_pred_test': y_pred_test,
                    'y_proba_test': y_proba_test,
                    'y_test': y_test
                }
                
            except Exception as e:
                st.warning(f"‚ö†Ô∏è Error entrenando {nombre}: {str(e)}")
                continue
        
        if not resultados_clf:
            st.error("‚ùå No se pudo entrenar ning√∫n modelo de clasificaci√≥n")
            return None
        
        # Mostrar resultados
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**üìä M√©tricas de Clasificaci√≥n**")
            df_metricas_clf = pd.DataFrame({
                modelo: {
                    'Precisi√≥n Entrenamiento': f"{res['acc_train']:.3f}",
                    'Precisi√≥n Prueba': f"{res['acc_test']:.3f}",
                    'Precision (Weighted)': f"{res['precision']:.3f}",
                    'Recall (Weighted)': f"{res['recall']:.3f}",
                    'F1-Score': f"{res['f1']:.3f}",
                    'Sobreajuste': 'S√≠' if res['acc_train'] - res['acc_test'] > 0.1 else 'No'
                }
                for modelo, res in resultados_clf.items()
            }).T
            
            st.dataframe(df_metricas_clf)
        
        with col2:
            # Matriz de confusi√≥n del mejor modelo
            mejor_modelo_clf = max(resultados_clf.keys(), key=lambda x: resultados_clf[x]['f1'])
            mejor_res_clf = resultados_clf[mejor_modelo_clf]
            
            from sklearn.metrics import confusion_matrix
            cm = confusion_matrix(mejor_res_clf['y_test'], mejor_res_clf['y_pred_test'])
            
            # Crear heatmap de matriz de confusi√≥n
            fig_cm = go.Figure(data=go.Heatmap(
                z=cm,
                x=['Vender (0)', 'Mantener (1)', 'Comprar (2)'],
                y=['Vender (0)', 'Mantener (1)', 'Comprar (2)'],
                colorscale='Blues',
                text=cm,
                texttemplate="%{text}",
                textfont={"size": 12}
            ))
            
            fig_cm.update_layout(
                title=f"Matriz de Confusi√≥n - {mejor_modelo_clf}",
                xaxis_title="Predicci√≥n",
                yaxis_title="Real",
                height=400
            )
            
            st.plotly_chart(fig_cm, use_container_width=True)
        
        # Interpretaci√≥n de se√±ales
        st.markdown("#### üì° Interpretaci√≥n de Se√±ales de Trading")
        
        etiquetas = {0: 'Vender', 1: 'Mantener', 2: 'Comprar'}
        
        # √öltima predicci√≥n
        if len(X_test_scaled) > 0:
            ultima_caracteristica = X_test_scaled[-1].reshape(1, -1)
            mejor_modelo_obj = resultados_clf[mejor_modelo_clf]['modelo']
            
            prediccion = mejor_modelo_obj.predict(ultima_caracteristica)[0]
            probabilidades = mejor_modelo_obj.predict_proba(ultima_caracteristica)[0]
            
            col1, col2, col3 = st.columns(3)
            
            col1.metric(
                "Se√±al Actual", 
                etiquetas[prediccion],
                help=f"Basado en modelo {mejor_modelo_clf}"
            )
            
            # Mostrar probabilidades
            for i, (etiqueta, prob) in enumerate(zip(etiquetas.values(), probabilidades)):
                color = "üü¢" if i == 2 else "üü°" if i == 1 else "üî¥"
                if i == 0:
                    col1.write(f"{color} {etiqueta}: {prob:.1%}")
                elif i == 1:
                    col2.write(f"{color} {etiqueta}: {prob:.1%}")
                else:
                    col3.write(f"{color} {etiqueta}: {prob:.1%}")
        
        # Evaluaci√≥n de performance
        acc_test = mejor_res_clf['acc_test']
        baseline_acc = 1/3  # Precisi√≥n aleatoria para 3 clases
        
        if acc_test > 0.6:
            st.success(f"‚úÖ **Excelente modelo**: Precisi√≥n del {acc_test:.1%} (vs {baseline_acc:.1%} aleatorio)")
        elif acc_test > 0.45:
            st.info(f"‚ÑπÔ∏è **Buen modelo**: Precisi√≥n del {acc_test:.1%} (vs {baseline_acc:.1%} aleatorio)")
        elif acc_test > 0.35:
            st.warning(f"‚ö†Ô∏è **Modelo moderado**: Precisi√≥n del {acc_test:.1%} (vs {baseline_acc:.1%} aleatorio)")
        else:
            st.error(f"‚ùå **Modelo deficiente**: Precisi√≥n del {acc_test:.1%} (apenas mejor que aleatorio)")
        
        return resultados_clf
        
    except Exception as e:
        st.error(f"Error en modelo de clasificaci√≥n: {str(e)}")
        return None

def red_neuronal_profunda_prediccion_precios(datos_precios, dias_prediccion=5, test_size=0.2):
    """
    Implementa una red neuronal profunda para predicci√≥n de precios usando TensorFlow/Keras
    """
    try:
        st.markdown("#### üß† Red Neuronal Profunda - Predicci√≥n de Precios")
        
        if datos_precios is None or len(datos_precios) < 200:
            st.warning("‚ö†Ô∏è Se requieren al menos 200 observaciones para entrenamiento de red neuronal")
            return None
        
        # Seleccionar activo principal (el primero o el de mayor volumen de datos)
        activo_principal = datos_precios.columns[0]
        precios = datos_precios[activo_principal].dropna()
        
        if len(precios) < 100:
            st.warning(f"‚ö†Ô∏è Datos insuficientes para {activo_principal}")
            return None
        
        # Normalizar precios
        scaler = MinMaxScaler(feature_range=(0, 1))
        precios_scaled = scaler.fit_transform(precios.values.reshape(-1, 1))
        
        # Crear secuencias para entrenamiento
        def crear_secuencias(data, ventana=60):
            X, y = [], []
            for i in range(ventana, len(data)):
                X.append(data[i-ventana:i, 0])
                y.append(data[i, 0])
            return np.array(X), np.array(y)
        
        ventana_tiempo = min(60, len(precios_scaled) // 4)
        X, y = crear_secuencias(precios_scaled, ventana_tiempo)
        
        if len(X) < 50:
            st.warning("‚ö†Ô∏è No hay suficientes secuencias para entrenamiento")
            return None
        
        # Dividir datos
        split_idx = int(len(X) * (1 - test_size))
        X_train, X_test = X[:split_idx], X[split_idx:]
        y_train, y_test = y[:split_idx], y[split_idx:]
        
        # Reshape para LSTM
        X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))
        X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))
        
        # Construir modelo
        modelo_lstm = keras.Sequential([
            layers.LSTM(50, return_sequences=True, input_shape=(ventana_tiempo, 1)),
            layers.Dropout(0.2),
            layers.LSTM(50, return_sequences=True),
            layers.Dropout(0.2),
            layers.LSTM(50),
            layers.Dropout(0.2),
            layers.Dense(25),
            layers.Dense(1)
        ])
        
        modelo_lstm.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])
        
        # Entrenar modelo
        with st.spinner("üß† Entrenando red neuronal profunda..."):
            history = modelo_lstm.fit(
                X_train, y_train,
                batch_size=32,
                epochs=50,
                validation_data=(X_test, y_test),
                verbose=0
            )
        
        # Hacer predicciones
        predicciones_train = modelo_lstm.predict(X_train, verbose=0)
        predicciones_test = modelo_lstm.predict(X_test, verbose=0)
        
        # Desnormalizar predicciones
        predicciones_train = scaler.inverse_transform(predicciones_train)
        predicciones_test = scaler.inverse_transform(predicciones_test)
        y_train_real = scaler.inverse_transform(y_train.reshape(-1, 1))
        y_test_real = scaler.inverse_transform(y_test.reshape(-1, 1))
        
        # Calcular m√©tricas
        mse_train = mean_squared_error(y_train_real, predicciones_train)
        mse_test = mean_squared_error(y_test_real, predicciones_test)
        r2_train = r2_score(y_train_real, predicciones_train)
        r2_test = r2_score(y_test_real, predicciones_test)
        
        # Mostrar resultados
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**üìä M√©tricas del Modelo LSTM**")
            st.metric("R¬≤ Entrenamiento", f"{r2_train:.4f}")
            st.metric("R¬≤ Prueba", f"{r2_test:.4f}")
            st.metric("MSE Entrenamiento", f"{mse_train:.2f}")
            st.metric("MSE Prueba", f"{mse_test:.2f}")
            
            if r2_test > 0.8:
                st.success("‚úÖ Excelente capacidad predictiva")
            elif r2_test > 0.6:
                st.info("‚ÑπÔ∏è Buena capacidad predictiva")
            elif r2_test > 0.3:
                st.warning("‚ö†Ô∏è Capacidad predictiva moderada")
            else:
                st.error("‚ùå Capacidad predictiva limitada")
        
        with col2:
            # Gr√°fico de p√©rdida durante entrenamiento
            fig_loss = go.Figure()
            fig_loss.add_trace(go.Scatter(
                y=history.history['loss'],
                name='P√©rdida Entrenamiento',
                line=dict(color='blue')
            ))
            fig_loss.add_trace(go.Scatter(
                y=history.history['val_loss'],
                name='P√©rdida Validaci√≥n',
                line=dict(color='red')
            ))
            
            fig_loss.update_layout(
                title="Evoluci√≥n de la P√©rdida",
                xaxis_title="√âpoca",
                yaxis_title="P√©rdida (MSE)",
                height=300
            )
            
            st.plotly_chart(fig_loss, use_container_width=True)
        
        # Gr√°fico de predicciones vs precios reales
        fechas_test = precios.index[split_idx + ventana_tiempo:]
        
        fig_pred = go.Figure()
        
        # Precios reales
        fig_pred.add_trace(go.Scatter(
            x=fechas_test,
            y=y_test_real.flatten(),
            name='Precios Reales',
            line=dict(color='blue')
        ))
        
        # Predicciones
        fig_pred.add_trace(go.Scatter(
            x=fechas_test,
            y=predicciones_test.flatten(),
            name='Predicciones LSTM',
            line=dict(color='red', dash='dash')
        ))
        
        fig_pred.update_layout(
            title=f"Predicciones vs Precios Reales - {activo_principal}",
            xaxis_title="Fecha",
            yaxis_title="Precio",
            height=500
        )
        
        st.plotly_chart(fig_pred, use_container_width=True)
        
        # Predicci√≥n futura
        st.markdown("#### üîÆ Predicci√≥n Futura")
        
        # Usar √∫ltimos datos para predecir
        ultimos_datos = precios_scaled[-ventana_tiempo:].reshape(1, ventana_tiempo, 1)
        
        predicciones_futuras = []
        datos_temp = ultimos_datos.copy()
        
        for _ in range(dias_prediccion):
            pred = modelo_lstm.predict(datos_temp, verbose=0)
            predicciones_futuras.append(pred[0, 0])
            
            # Actualizar datos temporales para siguiente predicci√≥n
            datos_temp = np.roll(datos_temp, -1, axis=1)
            datos_temp[0, -1, 0] = pred[0, 0]
        
        # Desnormalizar predicciones futuras
        predicciones_futuras = scaler.inverse_transform(np.array(predicciones_futuras).reshape(-1, 1))
        
        # Crear fechas futuras
        ultima_fecha = precios.index[-1]
        fechas_futuras = pd.date_range(start=ultima_fecha + timedelta(days=1), 
                                     periods=dias_prediccion, freq='D')
        
        # Mostrar predicciones futuras
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**üîÆ Predicciones Futuras**")
            precio_actual = precios.iloc[-1]
            
            for i, (fecha, precio_pred) in enumerate(zip(fechas_futuras, predicciones_futuras.flatten())):
                cambio = (precio_pred - precio_actual) / precio_actual * 100
                color = "üü¢" if cambio > 0 else "üî¥" if cambio < 0 else "üü°"
                st.write(f"{color} {fecha.strftime('%Y-%m-%d')}: ${precio_pred:.2f} ({cambio:+.1f}%)")
        
        with col2:
            # Gr√°fico de predicci√≥n futura
            fig_futuro = go.Figure()
            
            # √öltimos 30 d√≠as hist√≥ricos
            ultimos_30 = precios.tail(30)
            fig_futuro.add_trace(go.Scatter(
                x=ultimos_30.index,
                y=ultimos_30.values,
                name='Hist√≥rico',
                line=dict(color='blue')
            ))
            
            # Predicciones futuras
            fig_futuro.add_trace(go.Scatter(
                x=fechas_futuras,
                y=predicciones_futuras.flatten(),
                name='Predicci√≥n',
                line=dict(color='red', dash='dash'),
                marker=dict(size=8)
            ))
            
            fig_futuro.update_layout(
                title=f"Predicci√≥n Futura - {activo_principal}",
                xaxis_title="Fecha",
                yaxis_title="Precio",
                height=400
            )
            
            st.plotly_chart(fig_futuro, use_container_width=True)
        
        return {
            'modelo': modelo_lstm,
            'scaler': scaler,
            'historia': history,
            'metricas': {
                'r2_train': r2_train,
                'r2_test': r2_test,
                'mse_train': mse_train,
                'mse_test': mse_test
            },
            'predicciones_futuras': predicciones_futuras,
            'fechas_futuras': fechas_futuras
        }
        
    except Exception as e:
        st.error(f"Error en red neuronal profunda: {str(e)}")
        return None

def analisis_clustering_activos(datos_retornos, n_clusters=3):
    """
    Implementa an√°lisis de clustering para agrupar activos por comportamiento similar
    """
    try:
        st.markdown("#### üéØ An√°lisis de Clustering - Agrupaci√≥n de Activos")
        
        if datos_retornos is None or len(datos_retornos.columns) < 3:
            st.warning("‚ö†Ô∏è Se necesitan al menos 3 activos para clustering")
            return None
        
        # Calcular caracter√≠sticas para clustering
        caracteristicas = {}
        
        for activo in datos_retornos.columns:
            serie = datos_retornos[activo].dropna()
            
            if len(serie) < 20:
                continue
            
            caracteristicas[activo] = {
                'retorno_medio': serie.mean(),
                'volatilidad': serie.std(),
                'asimetria': serie.skew(),
                'curtosis': serie.kurtosis(),
                'var_95': np.percentile(serie, 5),
                'sharpe_ratio': serie.mean() / serie.std() if serie.std() > 0 else 0,
                'max_drawdown': (serie.cumsum() - serie.cumsum().expanding().max()).min()
            }
        
        if len(caracteristicas) < 3:
            st.warning("‚ö†Ô∏è No hay suficientes activos con datos v√°lidos")
            return None
        
        # Crear DataFrame de caracter√≠sticas
        df_features = pd.DataFrame(caracteristicas).T
        
        # Normalizar caracter√≠sticas
        scaler = StandardScaler()
        features_scaled = scaler.fit_transform(df_features.values)
        
        # Aplicar K-Means
        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
        clusters = kmeans.fit_predict(features_scaled)
        
        # A√±adir clusters al DataFrame
        df_features['Cluster'] = clusters
        
        # Mostrar resultados
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**üìä Activos por Cluster**")
            
            for i in range(n_clusters):
                activos_cluster = df_features[df_features['Cluster'] == i].index.tolist()
                
                with st.expander(f"üéØ Cluster {i+1} ({len(activos_cluster)} activos)"):
                    for activo in activos_cluster:
                        st.write(f"‚Ä¢ {activo}")
                    
                    # Estad√≠sticas del cluster
                    cluster_data = df_features[df_features['Cluster'] == i]
                    st.markdown("**Caracter√≠sticas promedio:**")
                    st.write(f"Retorno: {cluster_data['retorno_medio'].mean():.4f}")
                    st.write(f"Volatilidad: {cluster_data['volatilidad'].mean():.4f}")
                    st.write(f"Sharpe Ratio: {cluster_data['sharpe_ratio'].mean():.3f}")
        
        with col2:
            # Gr√°fico de dispersi√≥n 2D
            fig_scatter = go.Figure()
            
            colores = ['red', 'blue', 'green', 'orange', 'purple', 'brown', 'pink', 'gray']
            
            for i in range(n_clusters):
                mask = clusters == i
                fig_scatter.add_trace(go.Scatter(
                    x=df_features.loc[mask, 'retorno_medio'],
                    y=df_features.loc[mask, 'volatilidad'],
                    mode='markers+text',
                    text=df_features.index[mask],
                    textposition='top center',
                    name=f'Cluster {i+1}',
                    marker=dict(color=colores[i % len(colores)], size=10)
                ))
            
            fig_scatter.update_layout(
                title="Clusters: Retorno vs Volatilidad",
                xaxis_title="Retorno Medio",
                yaxis_title="Volatilidad",
                height=500
            )
            
            st.plotly_chart(fig_scatter, use_container_width=True)
        
        # An√°lisis de correlaciones dentro de clusters
        st.markdown("#### üîó An√°lisis de Correlaciones por Cluster")
        
        correlaciones_cluster = {}
        
        for i in range(n_clusters):
            activos_cluster = df_features[df_features['Cluster'] == i].index.tolist()
            
            if len(activos_cluster) > 1:
                corr_matrix = datos_retornos[activos_cluster].corr()
                correlaciones_cluster[f'Cluster {i+1}'] = {
                    'correlacion_promedio': corr_matrix.values[np.triu_indices_from(corr_matrix.values, k=1)].mean(),
                    'correlacion_min': corr_matrix.values[np.triu_indices_from(corr_matrix.values, k=1)].min(),
                    'correlacion_max': corr_matrix.values[np.triu_indices_from(corr_matrix.values, k=1)].max()
                }
        
        if correlaciones_cluster:
            df_corr = pd.DataFrame(correlaciones_cluster).T
            st.dataframe(df_corr.round(3))
        
        # Recomendaciones de diversificaci√≥n
        st.markdown("#### üí° Recomendaciones de Diversificaci√≥n")
        
        activos_por_cluster = []
        for i in range(n_clusters):
            activos_cluster = df_features[df_features['Cluster'] == i].index.tolist()
            activos_por_cluster.append(activos_cluster)
        
        # Calcular diversificaci√≥n actual
        cluster_counts = [len(activos) for activos in activos_por_cluster]
        diversificacion_score = 1 - (np.std(cluster_counts) / np.mean(cluster_counts)) if np.mean(cluster_counts) > 0 else 0
        
        if diversificacion_score > 0.8:
            st.success("‚úÖ **Excelente diversificaci√≥n**: Los activos est√°n bien distribuidos entre clusters")
        elif diversificacion_score > 0.6:
            st.info("‚ÑπÔ∏è **Buena diversificaci√≥n**: La distribuci√≥n entre clusters es razonable")
        else:
            st.warning("‚ö†Ô∏è **Diversificaci√≥n mejorable**: Considere balancear m√°s los activos entre clusters")
        
        # Sugerencias espec√≠ficas
        cluster_dominante = np.argmax(cluster_counts)
        if cluster_counts[cluster_dominante] > len(datos_retornos.columns) * 0.6:
            st.warning(f"‚ö†Ô∏è **Concentraci√≥n alta**: El Cluster {cluster_dominante+1} tiene {cluster_counts[cluster_dominante]} activos ({cluster_counts[cluster_dominante]/len(datos_retornos.columns)*100:.1f}%)")
            
            otros_clusters = [i for i in range(n_clusters) if i != cluster_dominante]
            st.info(f"üí° **Sugerencia**: Considere reducir exposici√≥n en Cluster {cluster_dominante+1} y aumentar en Clusters {[i+1 for i in otros_clusters]}")
        
        return {
            'clusters': clusters,
            'caracteristicas': df_features,
            'modelo_kmeans': kmeans,
            'scaler': scaler,
            'correlaciones_cluster': correlaciones_cluster
        }
        
    except Exception as e:
        st.error(f"Error en an√°lisis de clustering: {str(e)}")
        return None

def mostrar_analisis_machine_learning(portafolio, token_acceso, fecha_desde, fecha_hasta):
    """
    Funci√≥n principal que integra todos los an√°lisis de Machine Learning
    """
    st.markdown("### ü§ñ An√°lisis de Machine Learning")
    st.markdown("*Aplicando t√©cnicas avanzadas de inteligencia artificial para optimizaci√≥n y predicci√≥n*")
    
    # Obtener lista de s√≠mbolos del portafolio
    activos = portafolio.get('activos', [])
    simbolos = []
    
    for activo in activos:
        titulo = activo.get('titulo', {})
        simbolo = titulo.get('simbolo', '')
        if simbolo and simbolo not in simbolos:
            simbolos.append(simbolo)
    
    if not simbolos:
        st.warning("‚ö†Ô∏è No se encontraron s√≠mbolos v√°lidos en el portafolio")
        return
    
    if len(simbolos) < 2:
        st.warning("‚ö†Ô∏è Se necesitan al menos 2 activos para an√°lisis de ML")
        return
    
    # Obtener datos hist√≥ricos
    with st.spinner("üìä Cargando datos hist√≥ricos para an√°lisis ML..."):
        mean_returns, cov_matrix, datos_precios = get_historical_data_for_optimization(
            token_acceso, simbolos, fecha_desde, fecha_hasta
        )
    
    if datos_precios is None or len(datos_precios) < 30:
        st.error("‚ùå No hay suficientes datos hist√≥ricos para an√°lisis ML")
        return
    
    # Calcular retornos
    retornos = datos_precios.pct_change().dropna()
    
    # Crear tabs para diferentes an√°lisis ML
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "üìà Regresi√≥n Lineal",
        "üéØ Clasificaci√≥n",
        "üß† Redes Neuronales",
        "üéØ Clustering",
        "üìä M√©tricas ML"
    ])
    
    with tab1:
        # Modelo de regresi√≥n lineal
        resultados_regresion = modelo_regresion_lineal_portafolio(datos_precios)
        
        if resultados_regresion:
            st.markdown("#### üí° Interpretaci√≥n del An√°lisis de Regresi√≥n")
            st.markdown("""
            **¬øQu√© nos dice este an√°lisis?**
            - **R¬≤**: Mide qu√© porcentaje de la variabilidad de los retornos puede explicar el modelo
            - **MSE**: Error cuadr√°tico medio - valores m√°s bajos indican mejor ajuste
            - **Sobreajuste**: Cuando el modelo funciona mucho mejor en entrenamiento que en prueba
            
            **Aplicaciones pr√°cticas:**
            - Identificar qu√© activos son m√°s predictivos del rendimiento del portafolio
            - Detectar patrones lineales en los movimientos de precios
            - Validar supuestos de correlaci√≥n entre activos
            """)
    
    with tab2:
        # Modelo de clasificaci√≥n para se√±ales de trading
        resultados_clasificacion = modelo_clasificacion_se√±ales_trading(datos_precios)
        
        if resultados_clasificacion:
            st.markdown("#### üí° Interpretaci√≥n de Se√±ales de Trading")
            st.markdown("""
            **Metodolog√≠a:**
            - El modelo analiza caracter√≠sticas t√©cnicas hist√≥ricas
            - Clasifica per√≠odos futuros en: Vender (0), Mantener (1), Comprar (2)
            - Usa horizonte de predicci√≥n de 5 d√≠as
            
            **M√©tricas clave:**
            - **Precisi√≥n**: Porcentaje de predicciones correctas
            - **F1-Score**: Balance entre precisi√≥n y recall
            - **Matriz de Confusi√≥n**: Muestra tipos de errores del modelo
            
            **‚ö†Ô∏è Advertencia**: Este es un modelo educativo. No constituye asesoramiento financiero.
            """)
    
    with tab3:
        # Red neuronal profunda
        if len(datos_precios) >= 200:
            resultados_lstm = red_neuronal_profunda_prediccion_precios(datos_precios)
            
            if resultados_lstm:
                st.markdown("#### üí° Interpretaci√≥n de la Red Neuronal LSTM")
                st.markdown("""
                **Tecnolog√≠a LSTM (Long Short-Term Memory):**
                - Especializada en an√°lisis de secuencias temporales
                - Puede "recordar" patrones de largo plazo en los precios
                - Arquitectura profunda con m√∫ltiples capas y regularizaci√≥n
                
                **Interpretaci√≥n de resultados:**
                - **R¬≤ > 0.8**: Excelente capacidad predictiva
                - **R¬≤ 0.6-0.8**: Buena capacidad predictiva  
                - **R¬≤ < 0.6**: Capacidad predictiva limitada
                
                **Limitaciones:**
                - Los mercados son inherentemente impredecibles
                - El modelo se basa solo en datos hist√≥ricos de precios
                - Eventos fundamentales pueden cambiar radicalmente las tendencias
                """)
        else:
            st.warning("‚ö†Ô∏è Se requieren al menos 200 observaciones para entrenamiento de LSTM")
            st.info("üí° Intente ampliar el rango de fechas para obtener m√°s datos hist√≥ricos")
    
    with tab4:
        # An√°lisis de clustering
        if len(simbolos) >= 3:
            n_clusters = st.slider(
                "N√∫mero de clusters para agrupaci√≥n", 
                min_value=2, 
                max_value=min(len(simbolos), 6), 
                value=3
            )
            
            resultados_clustering = analisis_clustering_activos(retornos, n_clusters)
            
            if resultados_clustering:
                st.markdown("#### üí° Interpretaci√≥n del An√°lisis de Clustering")
                st.markdown("""
                **¬øQu√© es el clustering?**
                - Agrupa activos con comportamiento similar
                - Basado en retorno, volatilidad, asimetr√≠a y otras m√©tricas
                - √ötil para identificar oportunidades de diversificaci√≥n
                
                **Aplicaciones:**
                - **Diversificaci√≥n**: Seleccionar activos de diferentes clusters
                - **Gesti√≥n de riesgo**: Evitar concentraci√≥n en un solo cluster
                - **Rebalanceo**: Mantener exposici√≥n balanceada entre grupos
                
                **M√©tricas:**
                - **Correlaci√≥n intra-cluster**: Alta correlaci√≥n dentro del grupo
                - **Diversificaci√≥n**: Distribuci√≥n equilibrada entre clusters
                """)
        else:
            st.warning("‚ö†Ô∏è Se necesitan al menos 3 activos para clustering")
    
    with tab5:
        # M√©tricas avanzadas ML
        st.markdown("#### üìä M√©tricas Avanzadas de Machine Learning")
        
        # Calcular m√©tricas avanzadas
        metricas_ml = calcular_metricas_avanzadas_ml(retornos)
        
        if metricas_ml:
            # Organizar m√©tricas por activo
            activos_metricas = {}
            for key, value in metricas_ml.items():
                activo = key.split('_')[0]
                metrica = '_'.join(key.split('_')[1:])
                
                if activo not in activos_metricas:
                    activos_metricas[activo] = {}
                activos_metricas[activo][metrica] = value
            
            # Mostrar tabla resumen
            df_metricas_ml = pd.DataFrame(activos_metricas).T
            
            # Seleccionar m√©tricas m√°s importantes
            columnas_importantes = [col for col in df_metricas_ml.columns 
                                 if any(x in col for x in ['media', 'volatilidad', 'var_5', 'max_drawdown', 'sharpe'])]
            
            if columnas_importantes:
                st.dataframe(df_metricas_ml[columnas_importantes].round(4))
            
            # An√°lisis de riesgo avanzado
            st.markdown("#### ‚ö†Ô∏è An√°lisis de Riesgo Avanzado")
            
            riesgos_detectados = []
            
            for activo, metricas in activos_metricas.items():
                # Detectar alta volatilidad
                if 'volatilidad' in metricas and metricas['volatilidad'] > 0.05:
                    riesgos_detectados.append(f"üî¥ {activo}: Alta volatilidad ({metricas['volatilidad']:.3f})")
                
                # Detectar alto drawdown
                if 'max_drawdown' in metricas and metricas['max_drawdown'] < -0.2:
                    riesgos_detectados.append(f"üî¥ {activo}: Drawdown significativo ({metricas['max_drawdown']:.3f})")
                
                # Detectar asimetr√≠a negativa severa
                if 'asimetria' in metricas and metricas['asimetria'] < -1:
                    riesgos_detectados.append(f"üü° {activo}: Asimetr√≠a negativa ({metricas['asimetria']:.3f})")
            
            if riesgos_detectados:
                st.markdown("**üö® Riesgos Detectados:**")
                for riesgo in riesgos_detectados:
                    st.write(riesgo)
            else:
                st.success("‚úÖ No se detectaron riesgos significativos en el an√°lisis ML")
        
        # Recomendaciones finales
        st.markdown("#### üéØ Recomendaciones Basadas en ML")
        
        recomendaciones = [
            "üìä **Diversificaci√≥n**: Use los resultados de clustering para identificar activos complementarios",
            "üìà **Rebalanceo**: Considere los resultados de regresi√≥n para ajustar pesos del portafolio",
            "üéØ **Se√±ales**: Use la clasificaci√≥n como una herramienta adicional, no como √∫nica base para decisiones",
            "üß† **Predicciones**: Las redes neuronales pueden ayudar a identificar tendencias, pero siempre valide con an√°lisis fundamental",
            "‚ö†Ô∏è **Gesti√≥n de riesgo**: Monitoree las m√©tricas avanzadas regularmente para detectar cambios en el perfil de riesgo"
        ]
        
        for recomendacion in recomendaciones:
            st.markdown(recomendacion)
        
        st.markdown("---")
        st.markdown("**üìö Nota Educativa**: Todos los modelos de ML son herramientas de apoyo para el an√°lisis. La toma de decisiones de inversi√≥n debe considerar m√∫ltiples factores incluyendo an√°lisis fundamental, condiciones macroecon√≥micas y tolerancia al riesgo personal.")

def mostrar_optimizacion_portafolio(portafolio, token_acceso, fecha_desde, fecha_hasta):
    """
    Mejorar la funci√≥n de optimizaci√≥n con integraci√≥n de ML
    """
    st.markdown("### üéØ Optimizaci√≥n de Portafolio con Machine Learning")
    
    # Obtener s√≠mbolos del portafolio
    activos = portafolio.get('activos', [])
    simbolos = [activo.get('titulo', {}).get('simbolo', '') for activo in activos if activo.get('titulo')]
    simbolos = list(filter(None, simbolos))  # Eliminar vac√≠os
    
    if len(simbolos) < 2:
        st.warning("‚ö†Ô∏è Se necesitan al menos 2 activos en el portafolio para optimizaci√≥n")
        return
    
    # Obtener datos hist√≥ricos
    with st.spinner("üìä Cargando datos hist√≥ricos para optimizaci√≥n..."):
        mean_returns, cov_matrix, datos_precios = get_historical_data_for_optimization(
            token_acceso, simbolos, fecha_desde, fecha_hasta
        )
    
    if datos_precios is None or len(datos_precios) < 30:
        st.error("‚ùå No hay suficientes datos hist√≥ricos para optimizaci√≥n")
        return
    
    # Calcular retornos
    retornos = datos_precios.pct_change().dropna()
    
    # Optimizaci√≥n b√°sica
    st.markdown("#### ‚öôÔ∏è Optimizaci√≥n B√°sica")
    
    tipo_portafolio = st.selectbox(
        "Seleccione el tipo de optimizaci√≥n",
        options=[
            "markowitz", 
            "min-variance-l1", 
            "min-variance-l2", 
            "equi-weight"
        ],
        index=0
    )
    
    if tipo_portafolio == "markowitz":
        target_return = st.number_input(
            "Retorno objetivo (anualizado)", 
            value=0.0, 
            format="%.2f",
            help="Retorno esperado del portafolio en porcentaje"
        ) / 100
    else:
        target_return = None
    
    if st.button("üîÑ Ejecutar Optimizaci√≥n"):
        with st.spinner("Ejecutando optimizaci√≥n..."):
            if tipo_portafolio == "markowitz" and target_return is not None:
                resultado_opt = optimize_portfolio(retornos, target_return=target_return)
            else:
                resultado_opt = optimize_portfolio(retornos)
            
            if resultado_opt is not None:
                pesos = resultado_opt
                
                # Mostrar pesos optimizados
                st.markdown("#### üìä Pesos Optimizados")
                for i, simbolo in enumerate(retornos.columns):
                    st.write(f"‚Ä¢ {simbolo}: {pesos[i]:.2%}")
                
                # Gr√°fico de pesos
                fig_pesos = go.Figure(data=[go.Pie(
                    labels=retornos.columns,
                    values=pesos,
                    textinfo='label+percent',
                    hole=0.3
                )])
                fig_pesos.update_layout(title="Distribuci√≥n de Pesos en el Portafolio Optimo")
                st.plotly_chart(fig_pesos, use_container_width=True)
                
                # An√°lisis de riesgo con ML
                st.markdown("#### ü§ñ An√°lisis de Riesgo con Machine Learning")
                
                metricas_ml = calcular_metricas_avanzadas_ml(retornos)
                
                if metricas_ml:
                    # Organizar m√©tricas por activo
                    activos_metricas = {}
                    for key, value in metricas_ml.items():
                        activo = key.split('_')[0]
                        metrica = '_'.join(key.split('_')[1:])
                        
                        if activo not in activos_metricas:
                            activos_metricas[activo] = {}
                        activos_metricas[activo][metrica] = value
                    
                    # Mostrar tabla resumen
                    df_metricas_ml = pd.DataFrame(activos_metricas).T
                    
                    # Seleccionar m√©tricas m√°s importantes
                    columnas_importantes = [col for col in df_metricas_ml.columns 
                                         if any(x in col for x in ['media', 'volatilidad', 'var_5', 'max_drawdown', 'sharpe'])]
                    
                    if columnas_importantes:
                        st.dataframe(df_metricas_ml[columnas_importantes].round(4))
                    
                    # An√°lisis de riesgo avanzado
                    st.markdown("#### ‚ö†Ô∏è An√°lisis de Riesgo Avanzado")
                    
                    riesgos_detectados = []
                    
                    for activo, metricas in activos_metricas.items():
                        # Detectar alta volatilidad
                        if 'volatilidad' in metricas and metricas['volatilidad'] > 0.05:
                            riesgos_detectados.append(f"üî¥ {activo}: Alta volatilidad ({metricas['volatilidad']:.3f})")
                        
                        # Detectar alto drawdown
                        if 'max_drawdown' in metricas and metricas['max_drawdown'] < -0.2:
                            riesgos_detectados.append(f"üî¥ {activo}: Drawdown significativo ({metricas['max_drawdown']:.3f})")
                        
                        # Detectar asimetr√≠a negativa severa
                        if 'asimetria' in metricas and metricas['asimetria'] < -1:
                            riesgos_detectados.append(f"üü° {activo}: Asimetr√≠a negativa ({metricas['asimetria']:.3f})")
                    
                    if riesgos_detectados:
                        st.markdown("**üö® Riesgos Detectados:**")
                        for riesgo in riesgos_detectados:
                            st.write(riesgo)
                    else:
                        st.success("‚úÖ No se detectaron riesgos significativos en el an√°lisis ML")
        
        # Integraci√≥n de an√°lisis ML en la optimizaci√≥n
        if st.button("ü§ñ Analizar con Machine Learning"):
            mostrar_analisis_machine_learning(portafolio, token_acceso, fecha_desde, fecha_hasta)
